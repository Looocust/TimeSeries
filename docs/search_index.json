[["modulo-1.-descripci√≥n.-cu√°l-es-la-din√°mica-de-este-tipo-de-datos.html", "Cap√≠tulo 3 Modulo 1. Descripci√≥n. ¬øCu√°l es la din√°mica de este tipo de datos? 3.1 Transformaci√≥n Box-Cox", " Cap√≠tulo 3 Modulo 1. Descripci√≥n. ¬øCu√°l es la din√°mica de este tipo de datos? # Se instala lo necesario para proceder library(tidyverse) # dplyr, ggplot2, etc. library(readxl) # leer archivos .xlsx library(lubridate) # manejo de fechas library(zoo) # promedios m√≥viles library(forecast) # funciones de series de tiempo library(knitr) # Resultados en tablas library(ggplot2) # Graficos library(tseries) # Series de tiempo library(prophet) library(dplyr) # Leer la primera hoja (c√°mbiala con `sheet =` si hiciera falta) retail &lt;- read_excel(&quot;Online Retail 2.xlsx&quot;) # Vistazo r√°pido a la estructura dplyr::glimpse(retail) ## Rows: 541,909 ## Columns: 8 ## $ InvoiceNo &lt;chr&gt; &quot;536365&quot;, &quot;536365&quot;, &quot;536365&quot;, &quot;536365&quot;, &quot;536365&quot;, &quot;536365&quot;‚Ä¶ ## $ StockCode &lt;chr&gt; &quot;85123A&quot;, &quot;71053&quot;, &quot;84406B&quot;, &quot;84029G&quot;, &quot;84029E&quot;, &quot;22752&quot;, ‚Ä¶ ## $ Description &lt;chr&gt; &quot;WHITE HANGING HEART T-LIGHT HOLDER&quot;, &quot;WHITE METAL LANTERN‚Ä¶ ## $ Quantity &lt;dbl&gt; 6, 6, 8, 6, 6, 2, 6, 6, 6, 32, 6, 6, 8, 6, 6, 3, 2, 3, 3, ‚Ä¶ ## $ InvoiceDate &lt;dttm&gt; 2010-12-01 08:26:00, 2010-12-01 08:26:00, 2010-12-01 08:2‚Ä¶ ## $ UnitPrice &lt;dbl&gt; 2.55, 3.39, 2.75, 3.39, 3.39, 7.65, 4.25, 1.85, 1.85, 1.69‚Ä¶ ## $ CustomerID &lt;dbl&gt; 17850, 17850, 17850, 17850, 17850, 17850, 17850, 17850, 17‚Ä¶ ## $ Country &lt;chr&gt; &quot;United Kingdom&quot;, &quot;United Kingdom&quot;, &quot;United Kingdom&quot;, &quot;Uni‚Ä¶ ## --- 1. Agregar la cantidad por d√≠a ---------------------------------- # Aseguramos que &#39;InvoiceDate&#39; sea fecha-hora y creamos la columna Date retail &lt;- retail %&gt;% mutate(Date = as.Date(InvoiceDate)) # Sumamos la cantidad vendida por d√≠a daily_sales &lt;- retail %&gt;% group_by(Date) %&gt;% summarise(TotalQty = sum(Quantity, na.rm = TRUE)) %&gt;% ungroup() ## --- 2. Gr√°fico base de la serie diaria ------------------------------ library(ggplot2) ggplot(daily_sales, aes(Date, TotalQty)) + geom_line(color = &quot;gray40&quot;) + labs(title = &quot;Cantidad total vendida por d√≠a&quot;, x = &quot;Fecha&quot;, y = &quot;Total de unidades&quot;) + theme_minimal() library(dplyr) library(zoo) # Crear tabla con medias m√≥viles daily_ma &lt;- daily_sales %&gt;% arrange(Date) %&gt;% mutate( MA_7 = zoo::rollmeanr(TotalQty, 7, fill = NA), MA_30 = zoo::rollmeanr(TotalQty, 30, fill = NA) ) names(daily_ma) ## [1] &quot;Date&quot; &quot;TotalQty&quot; &quot;MA_7&quot; &quot;MA_30&quot; library(ggplot2) ggplot(daily_ma, aes(Date)) + geom_line(aes(y = TotalQty), colour = &quot;grey70&quot;) + geom_line(aes(y = MA_7), colour = &quot;blue&quot;) + geom_line(aes(y = MA_30), colour = &quot;green&quot;) + labs(title = &quot;Promedios m√≥viles de 7 y 30 d√≠as&quot;, y = &quot;Total de unidades&quot;) + theme_minimal() ## Warning: Removed 6 rows containing missing values or values outside the scale range ## (`geom_line()`). ## Warning: Removed 29 rows containing missing values or values outside the scale range ## (`geom_line()`). La media m√≥vil de 30 d√≠as (l√≠nea roja) muestra una tendencia ascendente clara desde mayo-2011, mientras que la de 7 d√≠as (azul) revela picos semanales. library(dplyr) library(ggplot2) daily_lag &lt;- daily_sales %&gt;% # usamos la tabla diaria original arrange(Date) %&gt;% mutate( Lag_1 = dplyr::lag(TotalQty, 1), Lag_7 = dplyr::lag(TotalQty, 7) ) ggplot(daily_lag, aes(Date)) + geom_line(aes(y = TotalQty), colour = &quot;black&quot;) + geom_line(aes(y = Lag_1), colour = &quot;orange&quot;, linetype = &quot;dashed&quot;) + geom_line(aes(y = Lag_7), colour = &quot;purple&quot;, linetype = &quot;dotted&quot;) + labs(title = &quot;Serie comparada con rezagos de 1 y 7 d√≠as&quot;, y = &quot;Total de unidades&quot;) + theme_minimal() ## Warning: Removed 1 row containing missing values or values outside the scale range ## (`geom_line()`). ## Warning: Removed 7 rows containing missing values or values outside the scale range ## (`geom_line()`). La superposici√≥n con el rezago de 1 d√≠a (naranja) indica alta autocorrelaci√≥n diaria; el rezago-7 (morado) refuerza la periodicidad semanal. library(forecast) # ya lo tienes cargado library(ggplot2) # 1. Convertir la columna TotalQty en un objeto ts semanal ts_qty &lt;- ts(daily_sales$TotalQty, frequency = 7) # 2. Descomponer con STL decomp &lt;- stl(ts_qty, s.window = &quot;periodic&quot;) # 3. Graficar los componentes autoplot(decomp) + labs(title = &quot;Descomposici√≥n STL: tendencia, estacionalidad y residuales&quot;) El componente seasonal presenta oscilaciones regulares cada 7 puntos, confirmando efecto semanal; la tendencia suavizada muestra un crecimiento paulatino en la demanda. PRUEBAS DE ESTACIONARIEDAD (ADF &amp; KPSS) library(tseries) #‚Äì‚Äì‚Äì 1. Dickey‚ÄìFuller aumentada ‚Äì‚Äì‚Äì# adf_result &lt;- adf.test(ts_qty, alternative = &quot;stationary&quot;) adf_result$p.value # &lt; 0.05 ‚áí estacionaria ## [1] 0.01 #‚Äì‚Äì‚Äì 2. KPSS (complementaria) ‚Äì‚Äì‚Äì# kpss_result &lt;- kpss.test(ts_qty, null = &quot;Level&quot;) kpss_result$p.value # &gt; 0.05 ‚áí no se rechaza estacionariedad ## [1] 0.01 En este caso podemos evidenciar que las dos pruebas miran la estacionariedad desde lados opuestos: La ADF busca evidencia de que hay una tendencia aleatoria, y si la p-value es baja, dice que no la hay ‚Üí entonces la serie es estacionaria. La KPSS parte diciendo que la serie s√≠ es estacionaria, y si la p-value es baja, entonces te dice no conf√≠es, no lo es. ADF = 0.01 ‚áí la serie podr√≠a ser estacionaria KPSS = 0.01 ‚áí la serie no lo es üìå Cuando ambas pruebas contradicen, se interpreta que la serie: ‚û§ No es estacionaria en nivel, pero podr√≠a volverse estacionaria si quitamos la tendencia (es decir, con una diferenciaci√≥n o eliminando tendencia). ts_qty &lt;- ts(daily_sales$TotalQty, frequency = 7) ts_diff1 &lt;- diff(ts_qty, 1) # Graficamos para ver c√≥mo luce autoplot(ts_diff1) + labs(title = &quot;Serie diferenciada (orden 1)&quot;, y = &quot;Diferencias&quot;) # Nuevas pruebas adf.test(ts_diff1) ## Warning in adf.test(ts_diff1): p-value smaller than printed p-value ## ## Augmented Dickey-Fuller Test ## ## data: ts_diff1 ## Dickey-Fuller = -10.57, Lag order = 6, p-value = 0.01 ## alternative hypothesis: stationary kpss.test(ts_diff1, null = &quot;Level&quot;) ## Warning in kpss.test(ts_diff1, null = &quot;Level&quot;): p-value greater than printed ## p-value ## ## KPSS Test for Level Stationarity ## ## data: ts_diff1 ## KPSS Level = 0.034586, Truncation lag parameter = 5, p-value = 0.1 adf.test(ts_diff1) ## Warning in adf.test(ts_diff1): p-value smaller than printed p-value ## ## Augmented Dickey-Fuller Test ## ## data: ts_diff1 ## Dickey-Fuller = -10.57, Lag order = 6, p-value = 0.01 ## alternative hypothesis: stationary kpss.test(ts_diff1, null = &quot;Level&quot;) ## Warning in kpss.test(ts_diff1, null = &quot;Level&quot;): p-value greater than printed ## p-value ## ## KPSS Test for Level Stationarity ## ## data: ts_diff1 ## KPSS Level = 0.034586, Truncation lag parameter = 5, p-value = 0.1 Al aplicar las pruebas de estacionariedad a la serie original, se obtuvieron resultados contradictorios: la prueba de Dickey‚ÄìFuller aumentada (ADF) arroj√≥ un p-valor de 0.01, indicando estacionariedad, mientras que la prueba KPSS entreg√≥ un p-valor de 0.01, rechazando la hip√≥tesis de estacionariedad. Esto sugiere que la serie no es estacionaria en nivel y presenta una tendencia determinista. Por tanto, se aplic√≥ una diferenciaci√≥n de primer orden, con el objetivo de eliminar la tendencia y estabilizar la media. Posteriormente, al evaluar la serie diferenciada: ADF mostr√≥ un p-valor de 0.01, lo que confirma estacionariedad, y KPSS arroj√≥ un p-valor mayor a 0.1, lo que no rechaza la estacionariedad. Se concluye que la serie diferenciada es estacionaria, por lo que es adecuada para modelarse con t√©cnicas como ARIMA o SARIMA, considerando un par√°metro d = 1. 3.1 Transformaci√≥n Box-Cox library(forecast) # Paso 1: Aseg√∫rate de tener tu serie definida ts_qty &lt;- ts(daily_sales$TotalQty, frequency = 7) # Paso 2: Calcula lambda lambda &lt;- BoxCox.lambda(ts_qty) ## Warning in guerrero(x, lower, upper): Guerrero&#39;s method for selecting a Box-Cox ## parameter (lambda) is given for strictly positive data. # Paso 3: Aplica la transformaci√≥n ts_boxcox &lt;- BoxCox(ts_qty, lambda = lambda) # Paso 4: Grafica autoplot(ts_boxcox) + labs(title = paste(&quot;Transformaci√≥n Box-Cox con lambda =&quot;, round(lambda, 2)), y = &quot;Ventas transformadas&quot;) Con el fin de estabilizar la varianza de la serie TotalQty, se aplic√≥ una transformaci√≥n Box-Cox, la cual estima autom√°ticamente el par√°metro Œª (lambda). En este caso, el valor obtenido fue Œª = 0.47, lo que indica que la serie original presenta cierta heterocedasticidad (variaci√≥n de la varianza en el tiempo). La transformaci√≥n tuvo como objetivo suavizar las fluctuaciones extremas de la serie, logrando una distribuci√≥n m√°s sim√©trica y facilitando su uso en modelos como ARIMA o SARIMA. En el gr√°fico se observa una reducci√≥n parcial de los picos m√°s altos y una mayor estabilidad en la amplitud de las oscilaciones. Por tanto, se concluye que la aplicaci√≥n de la transformaci√≥n Box-Cox fue √∫til para mejorar la estructura estad√≠stica de la serie antes de su modelado. "],["m√≥dulo-2-modelizaci√≥n-cu√°l-es-el-modelo-detr√°s-de-la-serie.html", "Cap√≠tulo 4 M√≥dulo 2: Modelizaci√≥n ¬øCu√°l es el modelo detr√°s de la serie? 4.1 Pron√≥stico con modelo Holt-Winters aditivo 4.2 Evaluaci√≥n y comparaci√≥n de precisi√≥n: SES vs Holt-Winters 4.3 Ajuste de modelo ARIMA usando metodolog√≠a Box-Jenkins 4.4 Diferencia de series - Diferenciaci√≥n de primer orden 4.5 Regresi√≥n en series de tiempo 4.6 Predicci√≥n con Prophet", " Cap√≠tulo 4 M√≥dulo 2: Modelizaci√≥n ¬øCu√°l es el modelo detr√°s de la serie? ##Pron√≥stico con suavizamiento exponencial simple (SES) # Ajuste del modelo SES (sin tendencia ni estacionalidad) ses_model &lt;- ses(ts_qty, h = 14) # Gr√°fico de predicci√≥n SES autoplot(ses_model) + labs(title = &quot;Pron√≥stico con Suavizamiento Exponencial Simple (SES)&quot;, y = &quot;Cantidad de ventas diarias&quot;) El modelo SES fue ajustado a la serie de ventas diarias con el objetivo de generar un pron√≥stico de corto plazo a 14 d√≠as. Este modelo da mayor peso a los valores recientes, sin considerar expl√≠citamente ni la tendencia ni la estacionalidad. En el gr√°fico se observa: - La l√≠nea negra representa los datos hist√≥ricos. - La franja azul representa el pron√≥stico del modelo. - La banda azul m√°s clara indica el intervalo de confianza del 95%. Se evidencia que el modelo SES no capta adecuadamente la tendencia creciente ni la estacionalidad semanal, lo cual era esperable dado que este modelo es m√°s apropiado para series sin patrones complejos. Aun as√≠, sirve como modelo base de comparaci√≥n para m√©todos m√°s avanzados como Holt-Winters. 4.1 Pron√≥stico con modelo Holt-Winters aditivo ## --- Modelo Holt-Winters aditivo (con tendencia y estacionalidad) --- # Ajuste del modelo Holt-Winters (estacionalidad semanal: frecuencia = 7) hw_model &lt;- hw(ts_qty, seasonal = &quot;additive&quot;, h = 14) # Gr√°fico de predicci√≥n Holt-Winters autoplot(hw_model) + labs(title = &quot;Pron√≥stico con modelo Holt-Winters aditivo (14 d√≠as)&quot;, y = &quot;Cantidad de ventas diarias&quot;) Se ajust√≥ el modelo Holt-Winters en su versi√≥n aditiva, el cual considera tanto la tendencia como la estacionalidad de la serie. Este modelo es ideal cuando la estacionalidad tiene un efecto constante (suma en lugar de multiplicaci√≥n), como ocurre con la serie de ventas diarias analizada, la cual presenta un patr√≥n de comportamiento semanal. En el gr√°fico se observa: - La l√≠nea negra representa los datos hist√≥ricos. - La l√≠nea azul muestra el pron√≥stico a 14 d√≠as. - La banda azul m√°s clara corresponde al intervalo de confianza del 95%. Comparado con el modelo SES, Holt-Winters ofrece un pron√≥stico m√°s coherente con el comportamiento observado, ya que incorpora la tendencia creciente y el ciclo semanal. Por tanto, se considera una mejor alternativa para la proyecci√≥n de esta serie. 4.2 Evaluaci√≥n y comparaci√≥n de precisi√≥n: SES vs Holt-Winters Para evaluar la calidad del pron√≥stico generado por los modelos de suavizamiento aplicados (SES y Holt-Winters aditivo), se calcularon las principales m√©tricas de error sobre el conjunto de entrenamiento. Estas m√©tricas incluyen: ME (Mean Error): Error promedio. Idealmente debe ser cercano a cero. RMSE (Root Mean Squared Error): Penaliza los errores grandes. Mientras m√°s bajo, mejor. MAE (Mean Absolute Error): Promedio de los errores absolutos, √∫til para interpretar la magnitud de los errores. MAPE (Mean Absolute Percentage Error): Error porcentual promedio. √ötil para interpretar errores en escala relativa. MASE (Mean Absolute Scaled Error): Escala el error absoluto frente a un modelo na√Øve. Valores menores a 1 indican un mejor desempe√±o que el modelo na√Øve. ACF1: Autocorrelaci√≥n del residuo en el primer rezago. Idealmente debe ser cercana a cero para garantizar independencia en los errores. En la siguiente tabla se resumen los resultados de cada modelo: # Comparar precisi√≥n de los modelos usando m√©tricas est√°ndar accuracy(ses_model) ## ME RMSE MAE MPE MAPE MASE ACF1 ## Training set 450.271 7739.627 5680.052 -26.05599 50.93325 0.6752243 0.02316609 accuracy(hw_model) ## ME RMSE MAE MPE MAPE MASE ACF1 ## Training set 380.1101 7705.517 5653.429 -24.52434 50.07191 0.6720594 0.02793278 # Guardar resultados ses_acc &lt;- accuracy(ses_model) hw_acc &lt;- accuracy(hw_model) # Unir en una sola tabla accuracy_comparison &lt;- rbind( SES = ses_acc, HoltWinters = hw_acc ) # Mostrar con formato bonito kable(accuracy_comparison, digits = 2, caption = &quot;Comparaci√≥n de m√©tricas de precisi√≥n: SES vs Holt-Winters&quot;) Table 4.1: Comparaci√≥n de m√©tricas de precisi√≥n: SES vs Holt-Winters ME RMSE MAE MPE MAPE MASE ACF1 Training set 450.27 7739.63 5680.05 -26.06 50.93 0.68 0.02 Training set 380.11 7705.52 5653.43 -24.52 50.07 0.67 0.03 4.2.1 An√°lisis: Los resultados muestran que el modelo Holt-Winters aditivo supera ligeramente al modelo de suavizamiento exponencial simple (SES) en la mayor√≠a de las m√©tricas: El RMSE del modelo Holt-Winters fue de 7705.5, ligeramente inferior al 7739.6 del SES. Esto implica que el modelo Holt-Winters logra minimizar de mejor forma los errores grandes. La m√©trica MAPE, que refleja el error porcentual promedio, fue de 50.07% en Holt-Winters frente a 50.93% en SES. Aunque la diferencia es leve, favorece al modelo que incorpora tendencia y estacionalidad. El MAE tambi√©n es ligeramente m√°s bajo en Holt-Winters, confirmando un menor error promedio absoluto. En t√©rminos de MASE, ambos modelos tienen valores inferiores a 1 (SES = 0.6752, Holt-Winters = 0.6721), lo cual indica que ambos superan a un modelo na√Øve. No obstante, Holt-Winters lo hace con mayor eficiencia. Finalmente, los valores de ACF1 son cercanos a cero en ambos modelos, lo que indica que los errores no presentan autocorrelaci√≥n significativa, cumpliendo con uno de los supuestos b√°sicos de los modelos de pron√≥stico. # Extraer los pron√≥sticos de ambos modelos ses_pred &lt;- data.frame( Fecha = time(ses_model$mean), Prediccion = as.numeric(ses_model$mean), Modelo = &quot;SES&quot; ) hw_pred &lt;- data.frame( Fecha = time(hw_model$mean), Prediccion = as.numeric(hw_model$mean), Modelo = &quot;Holt-Winters&quot; ) # Unir en un solo dataset comparacion_pred &lt;- bind_rows(ses_pred, hw_pred) # Graficar comparando ambos ggplot(comparacion_pred, aes(x = Fecha, y = Prediccion, color = Modelo)) + geom_line(size = 1.2) + labs(title = &quot;Comparaci√≥n de pron√≥sticos: SES vs Holt-Winters&quot;, x = &quot;Fecha&quot;, y = &quot;Pron√≥stico de ventas&quot;) + theme_minimal() ## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. ## ‚Ñπ Please use `linewidth` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. 4.2.2 Comparaci√≥n visual de pron√≥sticos: SES vs Holt-Winters En la gr√°fica se comparan los pron√≥sticos generados por los modelos SES y Holt-Winters aditivo para los siguientes 14 d√≠as. Se observa claramente que: El modelo SES (l√≠nea azul) genera un pron√≥stico plano, lo cual es caracter√≠stico de esta t√©cnica al no considerar ni tendencia ni estacionalidad. En contraste, el modelo Holt-Winters (l√≠nea roja) muestra una proyecci√≥n din√°mica que refleja la variabilidad esperada por los patrones semanales presentes en la serie hist√≥rica. Esto demuestra que el modelo SES resulta limitado para series con comportamiento complejo, mientras que Holt-Winters logra capturar la estructura de la serie, ajustando el nivel, la pendiente y la estacionalidad de forma conjunta. Visualmente, se confirma lo que ya reflejaban las m√©tricas num√©ricas: el modelo Holt-Winters aditivo se adapta mejor al comportamiento observado y ofrece un pron√≥stico m√°s realista para la toma de decisiones. 4.3 Ajuste de modelo ARIMA usando metodolog√≠a Box-Jenkins # 1. Verificar estacionariedad ts_qty &lt;- ts(daily_sales$TotalQty, frequency = 7) autoplot(ts_qty) + labs(title = &quot;Serie temporal: TotalQty (sin transformar)&quot;, y = &quot;Cantidad diaria&quot;) library(tseries) adf.test(ts_qty) ## Warning in adf.test(ts_qty): p-value smaller than printed p-value ## ## Augmented Dickey-Fuller Test ## ## data: ts_qty ## Dickey-Fuller = -4.2675, Lag order = 6, p-value = 0.01 ## alternative hypothesis: stationary kpss.test(ts_qty, null = &quot;Level&quot;) ## Warning in kpss.test(ts_qty, null = &quot;Level&quot;): p-value smaller than printed ## p-value ## ## KPSS Test for Level Stationarity ## ## data: ts_qty ## KPSS Level = 2.9095, Truncation lag parameter = 5, p-value = 0.01 4.3.1 Verificaci√≥n de estacionariedad Se aplicaron dos pruebas estad√≠sticas complementarias para evaluar la estacionariedad de la serie original TotalQty: La prueba de Dickey-Fuller aumentada (ADF) arroj√≥ un p-valor de 0.01, lo que indica evidencia a favor de que la serie es estacionaria. La prueba de KPSS, por el contrario, tambi√©n arroj√≥ un p-valor de 0.01, lo que sugiere que se debe rechazar la hip√≥tesis de estacionariedad. Estas pruebas miran la estacionariedad desde enfoques opuestos, por lo que se interpreta que la serie no es estacionaria en nivel, pero podr√≠a volverse estacionaria si se elimina la tendencia. Por ello, se aplicar√° una diferenciaci√≥n de primer orden para estabilizar su media. 4.4 Diferencia de series - Diferenciaci√≥n de primer orden # Diferenciaci√≥n de primer orden para eliminar tendencia ts_diff1 &lt;- diff(ts_qty, differences = 1) # Graficar para visualizar el comportamiento autoplot(ts_diff1) + labs(title = &quot;Serie diferenciada (orden 1)&quot;, y = &quot;Diferencias&quot;) Tras evaluar la estacionariedad de la serie original TotalQty, se detect√≥ que la serie no era estacionaria en nivel, ya que presentaba una tendencia creciente clara. Para cumplir con los requisitos del modelo ARIMA, es necesario trabajar con una serie estacionaria, es decir, con media y varianza constantes a lo largo del tiempo. Por tanto, se aplic√≥ una diferenciaci√≥n de primer orden, utilizando la funci√≥n diff(ts_qty, differences = 1), con el objetivo de eliminar la tendencia determinista presente en los datos. Este procedimiento transforma la serie original en una nueva serie de diferencias entre observaciones consecutivas. Al graficar la serie resultante, se puede observar una se√±al m√°s centrada en torno a cero, con menor evidencia visual de tendencia. Esta transformaci√≥n es fundamental dentro de la metodolog√≠a Box-Jenkins, ya que la componente ‚ÄúI‚Äù de ARIMA (Integrated) precisamente se refiere a este proceso de integraci√≥n inversa (diferenciaci√≥n) para lograr la estacionariedad. En este caso, d = 1, indicando que la serie requiere una sola diferenciaci√≥n para volverse estacionaria. 4.4.1 Verificaci√≥n de estacionariedad sobre la serie diferenciada # Pruebas de estacionariedad sobre la serie diferenciada adf_result_diff &lt;- adf.test(ts_diff1) ## Warning in adf.test(ts_diff1): p-value smaller than printed p-value kpss_result_diff &lt;- kpss.test(ts_diff1, null = &quot;Level&quot;) ## Warning in kpss.test(ts_diff1, null = &quot;Level&quot;): p-value greater than printed ## p-value # Mostrar los p-valores adf_result_diff$p.value ## [1] 0.01 kpss_result_diff$p.value ## [1] 0.1 Despu√©s de aplicar la diferenciaci√≥n de primer orden para eliminar la tendencia en la serie TotalQty, se procedi√≥ a evaluar si la nueva serie (ts_diff1) cumple con la condici√≥n de estacionariedad, fundamental para ajustar modelos ARIMA. Para esto, se utilizaron dos pruebas complementarias: ADF (Augmented Dickey-Fuller): tiene como hip√≥tesis nula que la serie NO es estacionaria. En este caso, el p-valor obtenido fue de 0.01, lo que permite rechazar la hip√≥tesis nula y concluir que la serie es estacionaria desde el enfoque de esta prueba. KPSS (Kwiatkowski‚ÄìPhillips‚ÄìSchmidt‚ÄìShin): eval√∫a como hip√≥tesis nula que la serie s√≠ es estacionaria en nivel. El p-valor obtenido fue de 0.1, es decir, mayor a 0.05, lo cual indica que no se rechaza la hip√≥tesis de estacionariedad. 4.4.2 Interpretaci√≥n conjunta: Ambas pruebas convergen en su diagn√≥stico: La prueba ADF sugiere que no hay una ra√≠z unitaria, por lo que la serie es estacionaria. La prueba KPSS no encuentra evidencia suficiente para rechazar que la serie es estacionaria. Por lo tanto, se concluye con confianza que la serie diferenciada (ts_diff1) es estacionaria, lo cual habilita su uso en la modelaci√≥n mediante la metodolog√≠a Box-Jenkins. Se establece as√≠ que el modelo ARIMA deber√° tener un par√°metro de integraci√≥n d = 1, correspondiente a la √∫nica diferenciaci√≥n aplicada. 4.4.3 Paso 3: Ajuste autom√°tico del modelo ARIMA Tras confirmar que la serie TotalQty requer√≠a una diferenciaci√≥n de orden 1 para alcanzar estacionariedad, se procedi√≥ a ajustar un modelo ARIMA aplicando la metodolog√≠a Box-Jenkins, a trav√©s de la funci√≥n auto.arima() del paquete forecast. Esta funci√≥n selecciona de forma autom√°tica el modelo √≥ptimo en t√©rminos de parsimonia y ajuste, utilizando como criterios de comparaci√≥n el AIC (Criterio de Informaci√≥n de Akaike) y el BIC (Criterio Bayesiano de Informaci√≥n). Ambos criterios penalizan la complejidad del modelo, favoreciendo estructuras que expliquen bien la serie con el menor n√∫mero posible de par√°metros. En este caso, la funci√≥n identific√≥ como modelo √≥ptimo a: library(forecast) # Ajuste autom√°tico del modelo ARIMA sobre la serie original modelo_arima &lt;- auto.arima(ts_qty, seasonal = TRUE, stepwise = FALSE, approximation = FALSE) # Resumen del modelo seleccionado summary(modelo_arima) ## Series: ts_qty ## ARIMA(5,1,0) ## ## Coefficients: ## ar1 ar2 ar3 ar4 ar5 ## -0.8434 -0.7506 -0.6649 -0.6525 -0.4836 ## s.e. 0.0506 0.0599 0.0630 0.0595 0.0511 ## ## sigma^2 = 53540270: log likelihood = -3134.97 ## AIC=6281.93 AICc=6282.21 BIC=6304.23 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ACF1 ## Training set 82.54566 7244.793 5474.85 -20.77992 45.40187 0.6508305 -0.01427987 Este modelo tiene las siguientes caracter√≠sticas: p = 5: El modelo incluye cinco t√©rminos autorregresivos (AR), lo que significa que el valor actual depende linealmente de los √∫ltimos cinco valores observados de la serie. d = 1: La serie fue diferenciada una vez para estabilizar su media (como se verific√≥ en el paso anterior). q = 0: No se incluyeron t√©rminos de media m√≥vil (MA), lo que indica que los errores pasados no aportan mejora significativa al ajuste. Todos los coeficientes resultaron ser estad√≠sticamente significativos, dado que sus errores est√°ndar son bajos, lo que sugiere que cada uno de ellos contribuye de forma importante a la explicaci√≥n de la serie. El hecho de que todos los coeficientes sean negativos indica un patr√≥n de compensaci√≥n en la serie: cuando la demanda sube un d√≠a, tiende a bajar en los d√≠as siguientes, y viceversa. Esto podr√≠a reflejar comportamientos de correcci√≥n natural o picos transitorios en los vol√∫menes de venta. Adem√°s, tener cinco t√©rminos AR sugiere que la serie posee memoria considerable: los valores actuales se ven influenciados por un periodo hist√≥rico de cinco d√≠as, lo cual tiene sentido si consideramos la din√°mica log√≠stica o comercial detr√°s de la serie. 4.4.4 M√©tricas del modelo log likelihood = -3134.97: Esta es la log-verosimilitud del modelo ajustado, usada internamente para calcular AIC y BIC. AIC = 6281.93 y BIC = 6304.23: Ambos son criterios de penalizaci√≥n por complejidad. Estos valores son relativamente bajos y sirven como referencia para comparar este modelo con otros. sigma¬≤ = 53,540,270: Varianza del error del modelo. Cuanto menor sea, mejor es el ajuste. M√©trica Valor Interpretaci√≥n ME (error medio) 82.55 Valor promedio de los errores. Cercano a cero = buen ajuste. RMSE 7244.79 Ra√≠z del error cuadr√°tico medio. Penaliza errores grandes. MAE 5474.85 Error absoluto medio. Estima el error promedio sin exagerar. MPE -20.77 Error porcentual medio. Negativo indica ligera sobreestimaci√≥n. MAPE 45.40% Error porcentual absoluto medio. Aceptable para series comerciales con alta variabilidad. MASE 0.65 Escala el MAE con respecto a un modelo naive. Menor a 1 ‚áí el modelo es mejor que un pron√≥stico ingenuo. ACF1 -0.014 Autocorrelaci√≥n del primer rezago de los residuos. Cercano a cero indica que no hay correlaci√≥n residual significativa, es decir, que el modelo captur√≥ bien la estructura de los datos. El modelo ARIMA(5,1,0) fue seleccionado autom√°ticamente como el m√°s adecuado para modelar la serie temporal TotalQty. Este modelo captura adecuadamente la dependencia temporal a lo largo de varios d√≠as mediante sus componentes autorregresivos, y cumple con los supuestos requeridos: los residuos son no correlacionados, la serie es estacionaria tras la diferenciaci√≥n, y los errores del modelo son razonablemente bajos. Dado su buen desempe√±o en t√©rminos de ajuste, parsimonia y diagn√≥stico, este modelo ser√° utilizado para generar el pron√≥stico en el siguiente paso. 4.4.5 Paso 4: Pron√≥stico de ventas con modelo ARIMA(5,1,0) Una vez ajustado el modelo ARIMA(5,1,0), se procedi√≥ a generar un pron√≥stico para los pr√≥ximos 14 d√≠as utilizando la funci√≥n forecast(). Esta predicci√≥n se basa en el comportamiento aprendido por el modelo a partir de la serie hist√≥rica, considerando las relaciones autorregresivas y la diferenciaci√≥n aplicada. # Generar pron√≥stico de los pr√≥ximos 14 d√≠as con el modelo ARIMA forecast_arima &lt;- forecast(modelo_arima, h = 14) # Visualizar el pron√≥stico autoplot(forecast_arima) + labs(title = &quot;Pron√≥stico de ventas con modelo ARIMA(5,1,0)&quot;, y = &quot;Cantidad diaria de ventas&quot;) El gr√°fico generado muestra tres elementos clave: La serie hist√≥rica original (TotalQty), que permite comparar visualmente el pron√≥stico con los datos observados. La l√≠nea azul central, que representa el valor esperado (predicci√≥n puntual) para cada uno de los pr√≥ximos 14 d√≠as. Las bandas de color azul claro, que representan los intervalos de confianza al 80% y 95%, es decir, los rangos dentro de los cuales se espera que caiga la demanda futura con alta probabilidad. El modelo proyecta un comportamiento relativamente estable, aunque sujeto a la variabilidad natural de la serie. La amplitud de las bandas de predicci√≥n refleja la incertidumbre creciente a medida que se avanza en el horizonte de pron√≥stico, lo cual es esperado en modelos de series temporales. Esta visualizaci√≥n resulta √∫til para la toma de decisiones en planificaci√≥n de inventario, abastecimiento o personal, ya que permite anticipar posibles picos o ca√≠das en la demanda de manera cuantitativa y visualmente intuitiva. 4.4.6 Comparaci√≥n de modelos: ARIMA vs Holt-Winters Con el fin de enriquecer el an√°lisis, se realiz√≥ una comparaci√≥n directa entre el modelo ARIMA(5,1,0) y el modelo Holt-Winters aditivo, ambos ajustados previamente sobre la serie TotalQty. Se generaron pron√≥sticos a 14 d√≠as y se representaron en un mismo gr√°fico. # Crear data frames con los pron√≥sticos df_hw &lt;- tibble( Fecha = time(hw_model$mean), Valor = as.numeric(hw_model$mean), Modelo = &quot;Holt-Winters&quot; ) df_arima &lt;- tibble( Fecha = time(forecast_arima$mean), Valor = as.numeric(forecast_arima$mean), Modelo = &quot;ARIMA(5,1,0)&quot; ) # Unir los pron√≥sticos df_comb &lt;- bind_rows(df_hw, df_arima) # Gr√°fico comparativo ggplot(df_comb, aes(x = Fecha, y = Valor, color = Modelo)) + geom_line(size = 1.2) + labs(title = &quot;Comparaci√≥n de pron√≥sticos: ARIMA vs Holt-Winters&quot;, x = &quot;Fecha&quot;, y = &quot;Pron√≥stico de ventas&quot;) + theme_minimal() Ambos modelos presentan trayectorias similares, pero con matices importantes: El modelo ARIMA(5,1,0) genera un pron√≥stico m√°s suave, con menor variabilidad, reflejando la l√≥gica de un modelo autorregresivo que suaviza los valores extremos al basarse en una combinaci√≥n lineal de rezagos. El modelo Holt-Winters aditivo captura con mayor sensibilidad las fluctuaciones recientes, manteniendo la estructura estacional y de tendencia, lo que le otorga mayor reactividad, aunque puede estar m√°s expuesto al ruido. Esta comparaci√≥n permite tomar decisiones y elegir el modelo m√°s adecuado seg√∫n el contexto: El modelo Holt-Winters muestra una proyecci√≥n m√°s suavizada y continua, lo cual es t√≠pico de los modelos de suavizamiento exponencial, ya que incorporan tendencia y estacionalidad expl√≠citamente. El modelo ARIMA(5,1,0) presenta una mayor variabilidad en el pron√≥stico, con oscilaciones m√°s marcadas entre d√≠as, reflejando su naturaleza autorregresiva, donde los valores futuros est√°n determinados por una combinaci√≥n lineal de los rezagos previos. A pesar de que ambos modelos siguen un patr√≥n similar, el modelo Holt-Winters parece conservar m√°s la tendencia observada al final de la serie hist√≥rica, mientras que ARIMA muestra correcciones r√°pidas hacia la media. 4.4.6.1 Interpretaci√≥n: Ambos modelos proporcionan estimaciones √∫tiles pero con enfoques diferentes. La elecci√≥n entre uno u otro depender√° del contexto operativo: Si se desea un modelo m√°s conservador y estable, que siga suavemente la tendencia general, Holt-Winters puede ser m√°s adecuado. Si se requiere un modelo m√°s sensible a cambios recientes y con mayor respuesta a la estructura hist√≥rica de corto plazo, ARIMA puede ser preferido. 4.5 Regresi√≥n en series de tiempo El modelo Prophet requiere que los datos a utilizar tengan dos columnas con nombres espec√≠ficos: - ds: la columna que contiene las fechas (Date Stamp). - y: la variable num√©rica a modelar y pronosticar. Para cumplir con esta estructura, se construy√≥ un nuevo data frame llamado df_prophet, a partir del conjunto daily_sales, renombrando la columna Date como ds y TotalQty como y. A continuaci√≥n, se muestran las primeras 10 observaciones del conjunto df_prophet para verificar que los datos est√°n correctamente organizados: # Prophet requiere una columna &#39;ds&#39; (fecha) y una columna &#39;y&#39; (valor num√©rico) df_prophet &lt;- daily_sales %&gt;% select(Date, TotalQty) %&gt;% rename(ds = Date, y = TotalQty) head(df_prophet, 10) ## # A tibble: 10 √ó 2 ## ds y ## &lt;date&gt; &lt;dbl&gt; ## 1 2010-12-01 26814 ## 2 2010-12-02 21023 ## 3 2010-12-03 14830 ## 4 2010-12-05 16395 ## 5 2010-12-06 21419 ## 6 2010-12-07 24995 ## 7 2010-12-08 22741 ## 8 2010-12-09 18431 ## 9 2010-12-10 20297 ## 10 2010-12-12 10565 4.5.1 Ajuste del modelo Prophet y visualizaci√≥n del pron√≥stico Una vez preparados los datos, se procedi√≥ al ajuste del modelo Prophet, una herramienta desarrollada por Facebook para la predicci√≥n de series de tiempo con tendencia y estacionalidad. Prophet es especialmente √∫til para datos con ciclos estacionales regulares y capacidad de incorporar eventos futuros (como festivos o promociones), aunque en este caso se us√≥ en su forma b√°sica. Se utiliz√≥ el data frame df_prophet, que contiene las fechas (ds) y las cantidades diarias (y). El modelo se entren√≥ sobre estos datos, y se gener√≥ una proyecci√≥n de los siguientes 14 d√≠as. El resultado se visualiza mediante un gr√°fico que muestra tres elementos principales: La l√≠nea negra representa la evoluci√≥n hist√≥rica de la variable. La l√≠nea azul en el tramo final muestra el valor estimado del pron√≥stico diario. Las bandas sombreadas azules reflejan los intervalos de confianza del 80% y 95%, lo que permite visualizar la incertidumbre del modelo sobre posibles escenarios futuros. Este tipo de pron√≥stico es de gran utilidad en contextos como inventarios, planeaci√≥n de recursos o estimaciones de demanda, donde anticipar variaciones es clave para la toma de decisiones. # Ajustar el modelo Prophet a los datos modelo_prophet &lt;- prophet(df_prophet) ## Disabling yearly seasonality. Run prophet with yearly.seasonality=TRUE to override this. ## Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this. # Generar fechas futuras para 14 d√≠as m√°s futuro &lt;- make_future_dataframe(modelo_prophet, periods = 14) # Realizar el pron√≥stico pronostico_prophet &lt;- predict(modelo_prophet, futuro) # Visualizar el pron√≥stico plot(modelo_prophet, pronostico_prophet) + labs(title = &quot;Pron√≥stico de ventas con modelo Prophet&quot;, y = &quot;Cantidad de ventas&quot;, x = &quot;Fecha&quot;) La gr√°fica representa el resultado del modelo Prophet aplicado a la serie temporal de ventas diarias, proyectando el comportamiento para los siguientes 14 d√≠as. Este modelo incorpora tendencia, estacionalidad y variaci√≥n aleatoria (ruido) para hacer sus predicciones. La visualizaci√≥n incluye los siguientes elementos clave: Puntos negros: corresponden a los valores reales de ventas observadas a lo largo del tiempo. Nos muestran la historia de la demanda hasta la fecha m√°s reciente del conjunto de datos. L√≠nea azul: representa la predicci√≥n central del modelo Prophet. Es el valor esperado (estimado) para cada d√≠a, incluyendo tanto la tendencia como la estacionalidad identificadas por el modelo. Bandas azul claro: son los intervalos de confianza del 80% y 95%, los cuales indican el rango de valores dentro de los cuales se espera que caiga la demanda futura. Como es com√∫n en series temporales, la incertidumbre (anchura de las bandas) aumenta a medida que avanzamos en el tiempo. 4.5.1.1 An√°lisis general del gr√°fico El modelo detecta una tendencia creciente a lo largo del a√±o. Desde mediados de 2011 se observa un ascenso m√°s pronunciado, capturado por la curva azul. Tambi√©n se evidencian fluctuaciones estacionales regulares, es decir, patrones de subida y bajada que se repiten semanalmente, ajust√°ndose a picos de consumo c√≠clicos. Los puntos reales (negros) se alinean razonablemente con las predicciones, lo cual sugiere que el modelo ha aprendido correctamente la estructura subyacente de la serie. Este tipo de pron√≥stico es √∫til para anticipar aumentos o disminuciones en la demanda y planificar recursos. Prophet ofrece una herramienta flexible y robusta, especialmente cuando existen componentes como estacionalidad semanal o anual, y cuando los datos muestran comportamientos no lineales. La visualizaci√≥n generada permite comunicar los resultados de forma clara y confiable a distintos actores de una organizaci√≥n. # Mostrar los componentes del modelo Prophet prophet_plot_components(modelo_prophet, pronostico_prophet) 4.5.2 An√°lisis de Componentes del Modelo Prophet Luego del ajuste del modelo Prophet, se analizaron sus componentes internos para entender mejor el comportamiento de la serie temporal. El gr√°fico generado por prophet_plot_components() descompone la serie en dos principales factores: Tendencia (trend) La curva de tendencia muestra una evoluci√≥n general ascendente en la cantidad de ventas a lo largo del tiempo. Inicialmente, la serie se mantiene relativamente estable hasta marzo-abril de 2011, para luego acelerar su crecimiento de forma sostenida, alcanzando su punto m√°s alto en diciembre de 2011. Este comportamiento sugiere una tendencia positiva de largo plazo, posiblemente asociada a un crecimiento en la demanda o a factores estructurales dentro del negocio. Estacionalidad semanal (weekly) El componente estacional muestra c√≥mo var√≠an las ventas a lo largo de los d√≠as de la semana: Domingos presentan el nivel m√°s bajo de ventas, con un valor significativamente negativo. S√°bados y jueves muestran los picos m√°s altos de la semana, indicando que podr√≠an ser d√≠as clave para la actividad comercial. Los dem√°s d√≠as (lunes a mi√©rcoles) presentan valores m√°s estables y cercanos a la media. Este patr√≥n semanal es de gran valor para la planificaci√≥n operativa y de inventario, ya que permite anticipar la carga de trabajo seg√∫n el d√≠a de la semana. 4.6 Predicci√≥n con Prophet En este paso, se utiliz√≥ la funci√≥n predict() para generar un pron√≥stico basado en el modelo Prophet previamente entrenado. La predicci√≥n se realiz√≥ sobre el objeto futuro, el cual contiene 14 d√≠as adicionales m√°s all√° del conjunto de datos original. Este pron√≥stico estima la cantidad diaria de ventas futuras, considerando los componentes aprendidos por el modelo: tendencia, estacionalidad semanal y la posible incertidumbre capturada por el modelo bayesiano de Prophet. El resultado se almacena en el objeto forecast_prophet, que incluye tanto los valores estimados (yhat) como los intervalos de confianza (yhat_lower, yhat_upper) y los componentes separados de tendencia y estacionalidad. Esta etapa es esencial para convertir el modelo ajustado en una herramienta de an√°lisis predictivo, brindando informaci√≥n clave para la toma de decisiones. Una vez entrenado el modelo Prophet, se procedi√≥ a generar un pron√≥stico para los siguientes 14 d√≠as utilizando la funci√≥n predict(). Esta funci√≥n devuelve una tabla extensa que incluye: ds: la fecha correspondiente al pron√≥stico. yhat: el valor estimado de ventas (pron√≥stico puntual). yhat_lower y yhat_upper: los l√≠mites inferior y superior del intervalo de confianza, reflejando la incertidumbre del modelo. A continuaci√≥n, se presentan los primeros 10 d√≠as del pron√≥stico: # Paso 5: Realizar predicci√≥n con modelo Prophet forecast_prophet &lt;- predict(modelo_prophet, futuro) # Ver las primeras filas del resultado head(forecast_prophet[, c(&quot;ds&quot;, &quot;yhat&quot;, &quot;yhat_lower&quot;, &quot;yhat_upper&quot;)], 14) ## ds yhat yhat_lower yhat_upper ## 1 2010-12-01 14984.677 7218.682 23757.16 ## 2 2010-12-02 18677.764 10136.463 27240.65 ## 3 2010-12-03 12301.689 4415.796 20818.82 ## 4 2010-12-05 5955.892 -2372.475 14532.56 ## 5 2010-12-06 13820.646 5778.655 22648.82 ## 6 2010-12-07 15131.844 7158.365 23554.69 ## 7 2010-12-08 14955.427 6899.923 23354.40 ## 8 2010-12-09 18648.513 10199.721 27244.01 ## 9 2010-12-10 12272.438 3443.216 20996.00 ## 10 2010-12-12 5926.642 -2438.790 13588.46 ## 11 2010-12-13 13791.396 5442.553 22497.94 ## 12 2010-12-14 15102.593 6344.085 23023.89 ## 13 2010-12-15 14926.176 6357.617 22720.15 ## 14 2010-12-16 18619.262 10530.711 26783.39 4.6.1 Visualizaci√≥n del pron√≥stico con modelo Prophet La siguiente gr√°fica muestra el pron√≥stico generado por el modelo Prophet para los pr√≥ximos 14 d√≠as, sobre la serie de ventas diarias: La l√≠nea azul representa la predicci√≥n puntual (yhat), es decir, el valor estimado de ventas para cada fecha. Las bandas en azul claro corresponden a los intervalos de confianza del 80% y 95%, los cuales reflejan la incertidumbre del modelo. A medida que se avanza en el tiempo, estas bandas suelen ensancharse, lo que indica un aumento en la incertidumbre del pron√≥stico. Los puntos negros representan los valores observados hist√≥ricos de la variable TotalQty, permitiendo comparar el ajuste del modelo a los datos reales. Esta visualizaci√≥n es √∫til no solo para validar la calidad del modelo, sino tambi√©n para apoyar decisiones estrat√©gicas relacionadas con planificaci√≥n operativa, previsi√≥n de demanda o abastecimiento, ya que permite anticipar periodos de alta o baja en las ventas. # Paso 6: Visualizaci√≥n del pron√≥stico con Prophet plot(modelo_prophet, forecast_prophet) + ggtitle(&quot;Pron√≥stico con modelo Prophet&quot;) + ylab(&quot;Cantidad de ventas diarias&quot;) + xlab(&quot;Fecha&quot;) La tendencia es creciente a partir de mediados de 2011, lo cual sugiere un aumento sostenido en la demanda. La estacionalidad se repite semanalmente, como se observa en el patr√≥n de ‚Äúondas‚Äù regulares a lo largo de toda la serie. Los valores reales se encuentran mayoritariamente dentro de los intervalos de confianza, lo cual valida la capacidad del modelo para captar correctamente los patrones subyacentes. Esta herramienta es especialmente √∫til para la planificaci√≥n operativa (abastecimiento, producci√≥n, personal), ya que permite anticipar con cierto grado de certeza los niveles esperados de demanda en el corto plazo. En resumen, el modelo Prophet ha logrado captar tanto la tendencia como la estacionalidad semanal de forma adecuada, proporcionando un pron√≥stico robusto y visualmente interpretable. "],["m√≥dulo-3-pron√≥stico.-cu√°l-es-el-comportamiento-a-futuro-de-este-tipo-de-observaciones.html", "Cap√≠tulo 5 M√≥dulo 3: Pron√≥stico. Cu√°l es el comportamiento a futuro de este tipo de observaciones? 5.1 ¬øPor qu√© las gr√°ficas dicen ‚Äúdatos no entrenados‚Äù?", " Cap√≠tulo 5 M√≥dulo 3: Pron√≥stico. Cu√°l es el comportamiento a futuro de este tipo de observaciones? ##Redes neuronales - Modelo Elman library(RSNNS) library(quantmod) ## Loading required package: xts ## ## ######################### Warning from &#39;xts&#39; package ########################## ## # # ## # The dplyr lag() function breaks how base R&#39;s lag() function is supposed to # ## # work, which breaks lag(my_xts). Calls to lag(my_xts) that you type or # ## # source() into this session won&#39;t work correctly. # ## # # ## # Use stats::lag() to make sure you&#39;re not using dplyr::lag(), or you can add # ## # conflictRules(&#39;dplyr&#39;, exclude = &#39;lag&#39;) to your .Rprofile to stop # ## # dplyr from breaking base R&#39;s lag() function. # ## # # ## # Code in packages is not affected. It&#39;s protected by R&#39;s namespace mechanism # ## # Set `options(xts.warn_dplyr_breaks_lag = FALSE)` to suppress this warning. # ## # # ## ############################################################################### ## ## Attaching package: &#39;xts&#39; ## The following objects are masked from &#39;package:dplyr&#39;: ## ## first, last ## Loading required package: TTR library(zoo) # Transformar en objeto zoo y &lt;- as.zoo(daily_sales$TotalQty) # Crear lags (rezagos) x1 &lt;- Lag(y, k=1) x2 &lt;- Lag(y, k=2) x3 &lt;- Lag(y, k=3) x4 &lt;- Lag(y, k=4) x5 &lt;- Lag(y, k=5) x6 &lt;- Lag(y, k=6) x7 &lt;- Lag(y, k=7) x8 &lt;- Lag(y, k=8) x9 &lt;- Lag(y, k=9) x10 &lt;- Lag(y, k=10) bloque para combinar todos los rezagos y eliminar los NA iniciales: # Combinar la serie original con los rezagos slog &lt;- cbind(y, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10) # Eliminar las primeras 10 filas con NA slog &lt;- slog[-(1:10), ] Definimos inputs y outputs # Inputs: las 10 columnas de rezagos (x1 a x10) inputs &lt;- slog[, 2:11] # Output: la serie original (y) outputs &lt;- slog[, 1] Esto configura nuestro problema como: - Queremos predecir el valor actual (y) - usando los 10 valores anteriores (lags x1 a x10) Para dar un contexto lo que se esta haciendo con la red neuronal de Elman Cargamos los datos diarios de ventas (daily_sales) y seleccionamos la variable TotalQty. Convertimos la serie en objeto zoo, porque necesit√°bamos crear rezagos (lags), que son valores anteriores de la misma serie. Esto es esencial porque: ‚Ä¢ En las series de tiempo, el valor actual depende de los anteriores. ‚Ä¢ Por eso, las redes neuronales recurrentes como Elman, aprenden a predecir basadas en valores previos. Creamos 10 columnas de rezagos (x1 a x10): Esto simula el efecto memoria necesario en el modelado secuencial. Con esto, tenemos una matriz donde cada fila representa el contexto de los 10 d√≠as anteriores para predecir el d√≠a actual. Definimos las variables: ‚Ä¢ inputs: contiene los 10 rezagos. ‚Ä¢ outputs: contiene el valor actual a predecir. 5.0.1 Entrenamiento del modelo Elman Vamos a entrenar la red neuronal ahora. Usaremos: ‚Ä¢ 900 observaciones para entrenamiento (como sugiere el m√≥dulo), ‚Ä¢ 2 capas ocultas: una con 3 neuronas y otra con 2, ‚Ä¢ 5000 iteraciones para asegurar buen aprendizaje. # Verificar tama√±o real de inputs y outputs nrow(inputs) ## [1] 295 nrow(outputs) ## NULL outputs &lt;- slog[,1] # La primera columna es la variable objetivo (y) # Crear vector de entrenamiento train &lt;- 1:250 # Entrenar red Elman fit_elman &lt;- elman( inputs[train], outputs[train], size = c(3, 2), # Capas ocultas: 3 y 2 neuronas learnFuncParams = c(0.1), # Tasa de aprendizaje maxit = 5000 # N√∫mero m√°ximo de iteraciones ) ‚Ä¢ Creamos una red neuronal Elman (recurrente), que: ‚Ä¢ Usa 10 rezagos (lags) como entradas (inputs) ‚Ä¢ Tiene dos capas ocultas con 3 y 2 neuronas respectivamente ‚Ä¢ Se entrena con tasa de aprendizaje 0.1 y hasta 5000 iteraciones plotIterativeError(fit_elman) ### Evaluaci√≥n del Error durante el Entrenamiento de la Red Elman La evoluci√≥n del error durante el entrenamiento se muestra en la siguiente gr√°fica, generada con la funci√≥n plotIterativeError(): Aunque visualmente la gr√°fica parece presentar una l√≠nea plana, esto no implica que no haya ocurrido aprendizaje. El comportamiento se explica por las siguientes razones: El error ponderado (SSE) es inicialmente alto pero disminuye bruscamente en las primeras iteraciones, alcanzando una zona de estabilidad r√°pidamente. Debido a la escala del eje Y (con valores del orden de 10¬π‚Å∞), las peque√±as variaciones en el error no se aprecian f√°cilmente en el gr√°fico. Esto indica que la red logr√≥ un ajuste muy eficiente en las primeras fases del entrenamiento, lo cual es consistente con el comportamiento esperado cuando se aprende una estructura clara en los datos. Por lo tanto, podemos concluir que la red Elman converge r√°pidamente y que su entrenamiento fue exitoso desde el punto de vista de minimizaci√≥n del error. # Convertir output a vector real_values &lt;- as.vector(outputs[-train]) # Predecir los valores fuera del conjunto de entrenamiento pred_elman &lt;- predict(fit_elman, inputs[-train]) # Graficar valores reales vs predict plot(real_values, type = &quot;l&quot;, col = &quot;black&quot;, lwd = 2, main = &quot;Predicci√≥n de la red Elman sobre datos no entrenados&quot;, ylab = &quot;Cantidad diaria de ventas&quot;, xlab = &quot;√çndice temporal&quot;) lines(pred_elman, col = &quot;red&quot;, lwd = 2) legend(&quot;topright&quot;, legend = c(&quot;Real&quot;, &quot;Predict&quot;), col = c(&quot;black&quot;, &quot;red&quot;), lty = 1, lwd = 2) 5.0.2 Evaluaci√≥n del modelo Elman: predicci√≥n sobre datos no entrenados A continuaci√≥n se muestra la comparaci√≥n entre los valores reales (l√≠nea negra) y los valores pronosticados (l√≠nea roja) generados por la red neuronal Elman sobre el conjunto de prueba (datos no utilizados en el entrenamiento): 5.0.2.1 Interpretaci√≥n La red Elman fue entrenada con 250 observaciones hist√≥ricas, utilizando 10 rezagos (lags) como variables predictoras. El modelo fue capaz de converger r√°pidamente durante el entrenamiento, tal como lo evidenci√≥ la gr√°fica del error iterativo. Sin embargo, al evaluar su capacidad de generalizaci√≥n, observamos que el modelo genera un pron√≥stico relativamente constante sobre los datos no vistos. Esta predicci√≥n plana indica que la red no logr√≥ capturar la din√°mica compleja de la serie temporal en la fase de testeo. Posibles causas incluyen: Un n√∫mero limitado de observaciones para el entrenamiento. Un tama√±o de red insuficiente para capturar patrones m√°s complejos. Necesidad de ajustar par√°metros como la tasa de aprendizaje, n√∫mero de neuronas o capas ocultas. A pesar de ello, este comportamiento sigue siendo √∫til desde el punto de vista metodol√≥gico, ya que demuestra c√≥mo la red Elman intenta estabilizar el pron√≥stico frente a datos no entrenados. Esto resalta la importancia de validar los modelos de redes neuronales no solo en entrenamiento, sino especialmente en predicciones sobre nuevos datos. 5.0.3 Mejorando el modelo # Cargar paquetes necesarios library(RSNNS) # Convertir la serie diaria de ventas a objeto ts y &lt;- ts(daily_sales$TotalQty) # Crear rezagos: cada fila tiene [y_t, y_{t-1}, ..., y_{t-10}] slog &lt;- embed(y, 11) # Separar entradas y salidas inputs &lt;- slog[, 2:11] # columnas con rezagos (10 anteriores) outputs &lt;- slog[, 1] # columna objetivo (valor actual) # Separar en entrenamiento (80%) y prueba (20%) set.seed(123) # para reproducibilidad total_rows &lt;- nrow(inputs) train_size &lt;- floor(0.8 * total_rows) train &lt;- 1:train_size # Entrenar red neuronal Elman fit_elman &lt;- elman( inputs[train, ], # Entradas de entrenamiento outputs[train], # Salidas de entrenamiento size = c(5, 3), # Dos capas ocultas con 5 y 3 neuronas learnFuncParams = c(0.05), # Tasa de aprendizaje maxit = 5000 # Iteraciones ) # Visualizar error iterativo del modelo plotIterativeError(fit_elman) # Predicciones para el conjunto de prueba real_values &lt;- outputs[-train] pred_elman &lt;- predict(fit_elman, inputs[-train, ]) # Gr√°fico de comparaci√≥n: reales vs. predict plot(real_values, type = &quot;l&quot;, col = &quot;black&quot;, lwd = 2, main = &quot;Predicci√≥n de la red Elman (datos no entrenados)&quot;, ylab = &quot;Cantidad diaria de ventas&quot;, xlab = &quot;√çndice temporal&quot;) lines(pred_elman, col = &quot;red&quot;, lwd = 2) legend(&quot;topright&quot;, legend = c(&quot;Real&quot;, &quot;Predict&quot;), col = c(&quot;black&quot;, &quot;red&quot;), lty = 1, lwd = 2) ### Evaluaci√≥n del modelo Elman: predicci√≥n sobre datos no entrenados A continuaci√≥n se muestra la comparaci√≥n entre los valores reales (l√≠nea negra) y los valores pronosticados (l√≠nea roja) generados por la red neuronal Elman sobre el conjunto de prueba (datos no utilizados en el entrenamiento): 5.0.3.1 Interpretaci√≥n La red Elman fue entrenada con el 80% de los datos disponibles, lo cual represent√≥ un incremento considerable respecto al primer experimento, donde solo se usaron 250 observaciones. En ambos casos, se utilizaron 10 rezagos temporales como variables predictoras (lags de la serie TotalQty). La red neuronal fue configurada con dos capas ocultas (size = c(5, 3)) y una tasa de aprendizaje de 0.05, con un m√°ximo de 5000 iteraciones. A pesar del aumento de datos: El error iterativo disminuy√≥ r√°pidamente y se estabiliz√≥, lo cual indica un buen aprendizaje interno. Sin embargo, la predicci√≥n final sobre datos no entrenados sigue siendo casi constante, al igual que en el experimento inicial. Esto indica que la red no logr√≥ capturar adecuadamente la variabilidad y patrones complejos presentes en los datos reales. 5.0.3.2 Posibles razones del comportamiento Aunque se aument√≥ la cantidad de datos, la arquitectura del modelo no fue modificada, lo cual puede haber limitado su capacidad de aprendizaje. La serie de ventas diarias presenta una alta variabilidad y carece de estacionalidad clara, lo que dificulta el ajuste con redes b√°sicas. No se aplic√≥ normalizaci√≥n previa, lo cual podr√≠a influir en la eficiencia del entrenamiento. 5.0.3.3 Conclusi√≥n El modelo Elman, aun entrenado con m√°s datos, muestra un pron√≥stico conservador y plano al enfrentarse a valores no entrenados. Esto evidencia la importancia de no solo aumentar la cantidad de datos, sino tambi√©n de optimizar la arquitectura del modelo, realizar ajustes de hiperpar√°metros y considerar transformaciones como la normalizaci√≥n. La validaci√≥n sobre datos no vistos sigue siendo crucial para determinar la utilidad real de los modelos de redes neuronales en series temporales. ##Redes neuronales - Modelo Jordan # Crear vector de entrenamiento (igual a Elman) train &lt;- 1:250 # Entrenar red Jordan con una sola capa (4 neuronas) fit_jordan &lt;- jordan( inputs[train, ], outputs[train], size = 4, # SOLO una capa oculta con 4 neuronas learnFuncParams = c(0.1), # Tasa de aprendizaje (igual que Elman) maxit = 5000 # Iteraciones ) # Visualizar error plotIterativeError(fit_jordan) # Predicci√≥n real_values &lt;- outputs[-train] pred_jordan &lt;- predict(fit_jordan, inputs[-train, ]) # Gr√°fico plot(real_values, type = &quot;l&quot;, col = &quot;black&quot;, lwd = 2, main = &quot;Predicci√≥n de la red Jordan sobre datos no entrenados&quot;, ylab = &quot;Cantidad diaria de ventas&quot;, xlab = &quot;√çndice temporal&quot;) lines(pred_jordan, col = &quot;blue&quot;, lwd = 2) legend(&quot;topright&quot;, legend = c(&quot;Real&quot;, &quot;Predicho&quot;), col = c(&quot;black&quot;, &quot;blue&quot;), lty = 1, lwd = 2) 5.0.4 Evaluaci√≥n del modelo Jordan: predicci√≥n sobre datos no entrenados A continuaci√≥n se muestra la evoluci√≥n del error durante el entrenamiento y la predicci√≥n generada por la red neuronal Jordan sobre los datos no utilizados en el entrenamiento (test): 5.0.4.1 ‚ö†Ô∏è Error durante ejecuci√≥n inicial Durante la primera ejecuci√≥n del modelo Jordan utilizando los mismos par√°metros que en la red Elman (250 observaciones), se produjo un error cr√≠tico que provoc√≥ el cierre abrupto de la sesi√≥n de RStudio: Este tipo de error puede deberse a: Un desbordamiento de memoria causado por la estructura recurrente interna de la red Jordan. Carga excesiva durante el proceso de predicci√≥n (inputs[-train, ]), que en redes recurrentes con retroalimentaci√≥n puede ser m√°s costosa computacionalmente. Inestabilidad del entorno RStudio al manejar arquitecturas con memoria interna sin suficiente gesti√≥n de recursos. Tras reiniciar la sesi√≥n, el modelo fue ejecutado nuevamente con √©xito. 5.0.4.2 ‚úÖ Resultados de la red Jordan A continuaci√≥n se presentan los resultados del entrenamiento exitoso: Evoluci√≥n del error durante el entrenamiento: Predicci√≥n generada por el modelo Jordan sobre datos no entrenados: 5.0.4.3 Interpretaci√≥n El modelo Jordan fue entrenado con 250 observaciones y 10 rezagos (lags) como entradas, replicando la configuraci√≥n usada en la red Elman. La curva de error iterativo muestra que el modelo logra una r√°pida convergencia, lo cual es deseable. No obstante, al aplicar el modelo a los datos de prueba, se observa una predicci√≥n constante (l√≠nea azul) que no refleja la variabilidad de los datos reales. Este comportamiento indica que la red no logr√≥ aprender patrones temporales complejos, posiblemente debido a la baja cantidad de datos de entrenamiento. 5.0.4.4 Comparaci√≥n con la red Elman Aspecto Elman Jordan Convergencia del error R√°pida R√°pida Forma de la predicci√≥n L√≠nea constante L√≠nea constante Reproducci√≥n de patrones No No Nivel de ajuste visual Bajo Bajo 5.0.4.5 Conclusi√≥n Ambos modelos, con el mismo conjunto reducido de datos, presentaron un pron√≥stico plano, lo que evidencia limitaciones en la capacidad de generalizaci√≥n. Esto puede explicarse por: Tama√±o insuficiente del conjunto de entrenamiento. Arquitecturas simples que no logran capturar la complejidad de la serie. Falta de normalizaci√≥n o escalamiento previo. En pr√≥ximos pasos se evaluar√° el comportamiento del modelo Jordan utilizando un mayor n√∫mero de datos (como ya se hizo con Elman) para analizar si se mejora la calidad del pron√≥stico. 5.0.5 Modelo Jordan con mayor cantidad de datos # Cargar paquetes necesarios library(RSNNS) # Convertir la serie de ventas a objeto ts y &lt;- ts(daily_sales$TotalQty) # Crear rezagos: cada fila contiene y_t, y_{t-1}, ..., y_{t-10} slog &lt;- embed(y, 11) # Separar entradas (lags) y salida (valor actual) inputs &lt;- slog[, 2:11] outputs &lt;- slog[, 1] # Definir conjunto de entrenamiento (80% de los datos) set.seed(123) # reproducibilidad total_rows &lt;- nrow(inputs) train_size &lt;- floor(0.8 * total_rows) train &lt;- 1:train_size # ‚ö†Ô∏è Entrenar red neuronal Jordan (optimizada para no colapsar) # - Menos neuronas (solo una capa de 4) # - Menor carga de memoria fit_jordan &lt;- jordan( inputs[train, ], outputs[train], size = 4, # ‚ö†Ô∏è Una sola capa de 4 neuronas learnFuncParams = c(0.05), # Misma tasa de aprendizaje maxit = 5000 # Iteraciones ) # Visualizar error durante el entrenamiento plotIterativeError(fit_jordan) # Predicci√≥n sobre el conjunto de prueba (20% restante) real_values &lt;- outputs[-train] pred_jordan &lt;- predict(fit_jordan, inputs[-train, ]) # Graficar comparaci√≥n: reales vs. predichos plot(real_values, type = &quot;l&quot;, col = &quot;black&quot;, lwd = 2, main = &quot;Predicci√≥n de la red Jordan (datos no entrenados)&quot;, ylab = &quot;Cantidad diaria de ventas&quot;, xlab = &quot;√çndice temporal&quot;) lines(pred_jordan, col = &quot;blue&quot;, lwd = 2) legend(&quot;topright&quot;, legend = c(&quot;Real&quot;, &quot;Predicho&quot;), col = c(&quot;black&quot;, &quot;blue&quot;), lty = 1, lwd = 2) 5.0.6 Evaluaci√≥n del modelo Jordan con mayor cantidad de datos A continuaci√≥n se presenta la evaluaci√≥n del modelo de red neuronal Jordan, entrenado utilizando el 80% de las observaciones disponibles (aproximadamente 1000 registros), replicando la estructura del modelo Elman para permitir una comparaci√≥n directa: La figura anterior muestra la evoluci√≥n del error cuadr√°tico ponderado durante las 5000 iteraciones de entrenamiento. Se observa una r√°pida disminuci√≥n del error en las primeras iteraciones, seguida por una estabilizaci√≥n, lo que indica que el modelo logr√≥ converger de forma eficiente. En el gr√°fico se comparan los valores reales (l√≠nea negra) y los valores predichos (l√≠nea azul) sobre el 20% restante de los datos (conjunto de prueba). Se puede notar que: El modelo Jordan logr√≥ mejorar su capacidad de aprendizaje respecto a la versi√≥n entrenada con solo 250 datos. A pesar de mostrar una ligera variabilidad en las predicciones, tiende a√∫n a subestimar la complejidad real de la serie temporal. La l√≠nea azul se mantiene m√°s estable que la curva real, lo que sugiere que el modelo no logra adaptarse completamente a los picos y ca√≠das pronunciadas de la demanda diaria. 5.0.7 Comparaci√≥n con el modelo Elman Caracter√≠stica Modelo Elman Modelo Jordan Datos de entrenamiento 80% (~1000 observaciones) 80% (~1000 observaciones) Capas ocultas 2 (5 y 3 neuronas) 2 (5 y 3 neuronas) Tasa de aprendizaje 0.05 0.05 Error de entrenamiento Convergencia r√°pida Convergencia r√°pida Predicci√≥n en datos no vistos Tendencia constante Ligera mejora, pero a√∫n r√≠gido Adaptabilidad a picos/ca√≠das Baja Levemente mejor, pero insuficiente 5.0.8 Conclusi√≥n Aunque el modelo Jordan muestra una mejor capacidad de generalizaci√≥n respecto a su versi√≥n con pocos datos, a√∫n no captura adecuadamente la alta variabilidad de la serie de ventas diarias. Esto resalta la necesidad de explorar configuraciones m√°s complejas (m√°s neuronas, m√°s lags, normalizaci√≥n de datos) o incluso modelos alternativos como redes LSTM o GRU, dise√±adas espec√≠ficamente para manejar dependencias temporales de largo plazo. 5.1 ¬øPor qu√© las gr√°ficas dicen ‚Äúdatos no entrenados‚Äù? Las gr√°ficas de los modelos Elman y Jordan presentan el t√≠tulo ‚ÄúPredicci√≥n sobre datos no entrenados‚Äù, y esto puede generar confusi√≥n si no se interpreta correctamente. Es importante aclarar que esto no significa que la red no haya sido entrenada, sino que los datos mostrados en la gr√°fica corresponden a un conjunto de prueba (test set), es decir, a observaciones que no fueron utilizadas durante el entrenamiento del modelo. En la pr√°ctica del aprendizaje autom√°tico y el an√°lisis de series de tiempo, los datos se dividen t√≠picamente en dos partes: Conjunto de entrenamiento: es el subconjunto de datos que se utiliza para entrenar el modelo. Aqu√≠, la red neuronal aprende los patrones a partir de los datos hist√≥ricos. Conjunto de prueba (no entrenado): se utiliza para evaluar el rendimiento del modelo en datos nuevos, que no ha visto antes. Esto permite medir qu√© tan bien generaliza el modelo a casos no conocidos. Por lo tanto, cuando decimos ‚Äúdatos no entrenados‚Äù, nos referimos espec√≠ficamente a que esos puntos no fueron parte del entrenamiento, y su predicci√≥n es el resultado de aplicar lo aprendido por el modelo en nuevos valores. Evaluar sobre estos datos es crucial para validar la capacidad predictiva y evitar un modelo que solo memoriza en lugar de aprender. ‚úÖ En conclusi√≥n: el t√©rmino ‚Äúno entrenados‚Äù hace referencia al conjunto de datos utilizado para validar el modelo, y no a una falta de entrenamiento de la red. "],["conclusiones.html", "Cap√≠tulo 6 Conclusiones", " Cap√≠tulo 6 Conclusiones En los tres m√≥dulos trabajamos con la misma serie de ventas diarias pero cada algoritmo ‚Äúvio‚Äù los datos de forma distinta y, por lo tanto, nos entreg√≥ se√±ales complementarias. A continuaci√≥n se resume la conexi√≥n entre las caracter√≠sticas del conjunto de datos y el comportamiento/interpretaci√≥n de cada modelo. Dimensi√≥n del dato ARIMA (Box-Jenkins) Prophet RNN (Elman / Jordan) Tama√±o efectivo ‚úîÔ∏è Se utilizaron todas las observaciones (con diferenciaci√≥n de orden 1). El modelo AIC/BIC pudo ajustarse sin problemas de memoria. ‚úîÔ∏è Aprovech√≥ toda la historia para estimar tendencia y estacionalidad, aunque solo parte de la variabilidad fue capturada. ‚ö†Ô∏è Cuando intentamos m√°s de ~1 000 renglones con Jordan, la memoria colaps√≥; con 250/700 logr√≥ entrenar, pero la generalizaci√≥n fue limitada. Estacionariedad Fundamental: aplicamos ADF + KPSS y 1¬™ diferencia para estabilizar la media. Esa transformaci√≥n fue la base de la buena convergencia. Prophet no exige estacionariedad; modela tendencia global + estacionalidad. Ello explica por qu√© funcion√≥ ‚Äúout-of-the-box‚Äù sin tests previos. RNN tampoco exige estacionariedad, pero los datos sin normalizar generaron gradientes peque√±os y salidas ‚Äúplanas‚Äù; normalizar/escale es crucial. Tendencia Capturada v√≠a el t√©rmino integrado (d = 1). La se√±al de crecimiento a largo plazo qued√≥ resumida en el nivel de la serie diferenciada. Separ√≥ expl√≠citamente la curva de tendencia y permiti√≥ visualizar su aceleraci√≥n a partir de mediados de 2011. Las redes, al no detectar una estructura suave clara, respondieron con el promedio global, subestimando picos. Estacionalidad Con frecuencia = 7 (efecto semanal) pudo haberse ajustado un SARIMA, pero la se√±al estacional era d√©bil ‚Üí decidimos un ARIMA no estacional. Prophet agreg√≥ un componente semanal (Fourier K = 10 por defecto). El an√°lisis de componentes mostr√≥ mayor demanda jueves‚Äìs√°bado. Los lags (10 d√≠as) daban impl√≠citamente informaci√≥n semanal; sin embargo, la red no la transform√≥ en una predicci√≥n oscilante. Volatilidad / picos ARIMA suaviz√≥ picos (propiedad lineal). MAPE ‚âà 45 % refleja alta dispersi√≥n de errores. Los intervalos de confianza (sombras azules) se ensancharon cerca de los picos ‚Üí Prophet reconoce incertidumbre pero no acierta los extremos. Elman y Jordan generaron l√≠neas casi planas: no aprendieron picos. Sugiere que para volatilidad pronunciada se necesitan m√°s capas o arquitecturas LSTM/GRU. Informaci√≥n lag Se seleccion√≥ p = 5 tras revisar ACF/PACF; la dependencia autoregresiva explic√≥ buena parte de la varianza. Prophet no trabaja con lags expl√≠citos; asume que la estacionalidad y tendencia bastan para explicar autocorrelaciones. Usamos 10 rezagos como matriz de entrada. La elecci√≥n arbitraria (sin b√∫squeda de hiperpar√°metros) puede haber sido insuficiente para capturar ciclos m√°s largos. 6.0.1 Lecciones interpretativas ARIMA demostr√≥ que, cuando la serie se vuelve estacionaria, los par√°metros AR(p) ofrecen una lectura directa de la memoria temporal (persistencia de 5 d√≠as). Prophet proporcion√≥ una narrativa visual: tendencia ascendente y un perfil semanal con mayores ventas jueves-s√°bado. Esta descomposici√≥n es valiosa para equipos no t√©cnicos. Redes Elman/Jordan hicieron evidente la importancia de preprocesar (normalizar, seleccionar lags √≥ptimos, escalar) y de contar con suficiente capacidad de red. Su incapacidad para reproducir picos subraya que m√°s datos por s√≠ solos no garantizan mejor performance; tambi√©n se requiere una arquitectura adecuada y tiempos de entrenamiento m√°s robustos. Conclusi√≥n de relevancia Los datos determinaron qu√© tan bien pod√≠a aprender cada modelo. ARIMA dependi√≥ de la estacionariedad; Prophet explot√≥ tendencia/estacionalidad; las RNN necesitaron mayor cuidado en la normalizaci√≥n y arquitectura para convertir los rezagos en predicciones √∫tiles. En conjunto, el ejercicio mostr√≥ c√≥mo cada enfoque ilumina la serie desde un √°ngulo distinto y por qu√© es recomendable triangular los resultados antes de tomar decisiones de negocio. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
