# Modulo 1. Descripci√≥n. ¬øCu√°l es la din√°mica de este tipo de datos?



```{r setup, message=FALSE}
# Se instala lo necesario para proceder

library(tidyverse)   # dplyr, ggplot2, etc.
library(readxl)      # leer archivos .xlsx
library(lubridate)   # manejo de fechas
library(zoo)         # promedios m√≥viles
library(forecast)    # funciones de series de tiempo
library(knitr)       # Resultados en tablas
library(ggplot2)     # Graficos
library(tseries)     # Series de tiempo
library(prophet)
library(dplyr)

```

```{r cargar-datos}
# Leer la primera hoja (c√°mbiala con `sheet =` si hiciera falta)
retail <- read_excel("Online Retail 2.xlsx")

# Vistazo r√°pido a la estructura
dplyr::glimpse(retail)

```

```{r}
## --- 1. Agregar la cantidad por d√≠a ----------------------------------
# Aseguramos que 'InvoiceDate' sea fecha-hora y creamos la columna Date
retail <- retail %>% 
  mutate(Date = as.Date(InvoiceDate))

# Sumamos la cantidad vendida por d√≠a
daily_sales <- retail %>% 
  group_by(Date) %>% 
  summarise(TotalQty = sum(Quantity, na.rm = TRUE)) %>% 
  ungroup()

## --- 2. Gr√°fico base de la serie diaria ------------------------------
library(ggplot2)

ggplot(daily_sales, aes(Date, TotalQty)) +
  geom_line(color = "gray40") +
  labs(title = "Cantidad total vendida por d√≠a",
       x = "Fecha", y = "Total de unidades") +
  theme_minimal()

```

```{r}
library(dplyr)
library(zoo)

# Crear tabla con medias m√≥viles
daily_ma <- daily_sales %>% 
  arrange(Date) %>% 
  mutate(
    MA_7  = zoo::rollmeanr(TotalQty,  7, fill = NA),
    MA_30 = zoo::rollmeanr(TotalQty, 30, fill = NA)
  )
names(daily_ma)

```

```{r}
library(ggplot2)

ggplot(daily_ma, aes(Date)) +
  geom_line(aes(y = TotalQty), colour = "grey70") +
  geom_line(aes(y = MA_7),  colour = "blue") +
  geom_line(aes(y = MA_30), colour = "green") +
  labs(title = "Promedios m√≥viles de 7 y 30 d√≠as",
       y = "Total de unidades") +
  theme_minimal()
```
 La media m√≥vil de 30 d√≠as (l√≠nea roja) muestra una tendencia ascendente clara desde mayo-2011, mientras que la de 7 d√≠as (azul) revela picos semanales.


```{r rezagos, message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)

daily_lag <- daily_sales %>%               # usamos la tabla diaria original
  arrange(Date) %>% 
  mutate(
    Lag_1 = dplyr::lag(TotalQty, 1),
    Lag_7 = dplyr::lag(TotalQty, 7)
  )

```

```{r}
ggplot(daily_lag, aes(Date)) +
  geom_line(aes(y = TotalQty), colour = "black") +
  geom_line(aes(y = Lag_1), colour = "orange",  linetype = "dashed") +
  geom_line(aes(y = Lag_7), colour = "purple",  linetype = "dotted") +
  labs(title = "Serie comparada con rezagos de 1 y 7 d√≠as",
       y = "Total de unidades") +
  theme_minimal()

```
La superposici√≥n con el rezago de 1 d√≠a (naranja) indica alta autocorrelaci√≥n diaria; el rezago-7 (morado) refuerza la periodicidad semanal.

```{r estacionalidad, message=FALSE, warning=FALSE}
library(forecast)   # ya lo tienes cargado
library(ggplot2)

# 1. Convertir la columna TotalQty en un objeto ts semanal
ts_qty <- ts(daily_sales$TotalQty, frequency = 7)

# 2. Descomponer con STL
decomp <- stl(ts_qty, s.window = "periodic")

# 3. Graficar los componentes
autoplot(decomp) +
  labs(title = "Descomposici√≥n STL: tendencia, estacionalidad y residuales")
```
El componente seasonal presenta oscilaciones regulares cada 7 puntos, confirmando efecto semanal; la tendencia suavizada muestra un crecimiento paulatino en la demanda.



PRUEBAS DE ESTACIONARIEDAD (ADF & KPSS)

```{r adf-kpss, message=FALSE, warning=FALSE}
library(tseries)

#‚Äì‚Äì‚Äì 1. Dickey‚ÄìFuller aumentada ‚Äì‚Äì‚Äì#
adf_result  <- adf.test(ts_qty, alternative = "stationary")
adf_result$p.value      # < 0.05  ‚áí  estacionaria

#‚Äì‚Äì‚Äì 2. KPSS (complementaria) ‚Äì‚Äì‚Äì#
kpss_result <- kpss.test(ts_qty, null = "Level")
kpss_result$p.value     # > 0.05  ‚áí  no se rechaza estacionariedad

```

En este caso podemos evidenciar que las dos pruebas miran la estacionariedad desde lados opuestos:

La ADF busca evidencia de que hay una tendencia aleatoria, y si la p-value es baja, dice que no la hay ‚Üí entonces la serie es estacionaria.

La KPSS parte diciendo que la serie s√≠ es estacionaria, y si la p-value es baja, entonces te dice no conf√≠es, no lo es.

ADF = 0.01 ‚áí la serie podr√≠a ser estacionaria

KPSS = 0.01 ‚áí la serie no lo es

üìå Cuando ambas pruebas contradicen, se interpreta que la serie:

‚û§ No es estacionaria en nivel,
pero podr√≠a volverse estacionaria si quitamos la tendencia
(es decir, con una diferenciaci√≥n o eliminando tendencia).



```{r}
ts_qty <- ts(daily_sales$TotalQty, frequency = 7)

ts_diff1 <- diff(ts_qty, 1)

# Graficamos para ver c√≥mo luce
autoplot(ts_diff1) + 
  labs(title = "Serie diferenciada (orden 1)", y = "Diferencias")

# Nuevas pruebas
adf.test(ts_diff1)
kpss.test(ts_diff1, null = "Level")

```



```{r}
adf.test(ts_diff1)
kpss.test(ts_diff1, null = "Level")

```
Al aplicar las pruebas de estacionariedad a la serie original, se obtuvieron resultados contradictorios: la prueba de Dickey‚ÄìFuller aumentada (ADF) arroj√≥ un p-valor de 0.01, indicando estacionariedad, mientras que la prueba KPSS entreg√≥ un p-valor de 0.01, rechazando la hip√≥tesis de estacionariedad.

Esto sugiere que la serie no es estacionaria en nivel y presenta una tendencia determinista. Por tanto, se aplic√≥ una diferenciaci√≥n de primer orden, con el objetivo de eliminar la tendencia y estabilizar la media.

Posteriormente, al evaluar la serie diferenciada:

ADF mostr√≥ un p-valor de 0.01, lo que confirma estacionariedad, y

KPSS arroj√≥ un p-valor mayor a 0.1, lo que no rechaza la estacionariedad.

Se concluye que la serie diferenciada es estacionaria, por lo que es adecuada para modelarse con t√©cnicas como ARIMA o SARIMA, considerando un par√°metro d = 1.

## Transformaci√≥n Box-Cox

```{r}
library(forecast)

# Paso 1: Aseg√∫rate de tener tu serie definida
ts_qty <- ts(daily_sales$TotalQty, frequency = 7)

# Paso 2: Calcula lambda
lambda <- BoxCox.lambda(ts_qty)

# Paso 3: Aplica la transformaci√≥n
ts_boxcox <- BoxCox(ts_qty, lambda = lambda)

# Paso 4: Grafica
autoplot(ts_boxcox) +
  labs(title = paste("Transformaci√≥n Box-Cox con lambda =", round(lambda, 2)),
       y = "Ventas transformadas")


```

Con el fin de estabilizar la varianza de la serie `TotalQty`, se aplic√≥ una transformaci√≥n Box-Cox, la cual estima autom√°ticamente el par√°metro Œª (lambda). En este caso, el valor obtenido fue Œª = 0.47, lo que indica que la serie original presenta cierta heterocedasticidad (variaci√≥n de la varianza en el tiempo).

La transformaci√≥n tuvo como objetivo suavizar las fluctuaciones extremas de la serie, logrando una distribuci√≥n m√°s sim√©trica y facilitando su uso en modelos como ARIMA o SARIMA. En el gr√°fico se observa una reducci√≥n parcial de los picos m√°s altos y una mayor estabilidad en la amplitud de las oscilaciones.

Por tanto, se concluye que la aplicaci√≥n de la transformaci√≥n Box-Cox **fue √∫til** para mejorar la estructura estad√≠stica de la serie antes de su modelado.



# M√≥dulo 2: Modelizaci√≥n ¬øCu√°l es el modelo detr√°s de la serie?

##Pron√≥stico con suavizamiento exponencial simple (SES)

```{r}
# Ajuste del modelo SES (sin tendencia ni estacionalidad)
ses_model <- ses(ts_qty, h = 14)

# Gr√°fico de predicci√≥n SES
autoplot(ses_model) +
  labs(title = "Pron√≥stico con Suavizamiento Exponencial Simple (SES)",
       y = "Cantidad de ventas diarias")
```

El modelo SES fue ajustado a la serie de ventas diarias con el objetivo de generar un pron√≥stico de corto plazo a 14 d√≠as. Este modelo da mayor peso a los valores recientes, sin considerar expl√≠citamente ni la tendencia ni la estacionalidad.

En el gr√°fico se observa:
- La l√≠nea negra representa los datos hist√≥ricos.
- La franja azul representa el pron√≥stico del modelo.
- La banda azul m√°s clara indica el intervalo de confianza del 95%.

Se evidencia que el modelo SES **no capta adecuadamente la tendencia creciente ni la estacionalidad semanal**, lo cual era esperable dado que este modelo es m√°s apropiado para series sin patrones complejos. Aun as√≠, sirve como modelo base de comparaci√≥n para m√©todos m√°s avanzados como Holt-Winters.


## Pron√≥stico con modelo Holt-Winters aditivo


```{r}
## --- Modelo Holt-Winters aditivo (con tendencia y estacionalidad) ---
# Ajuste del modelo Holt-Winters (estacionalidad semanal: frecuencia = 7)
hw_model <- hw(ts_qty, seasonal = "additive", h = 14)

# Gr√°fico de predicci√≥n Holt-Winters
autoplot(hw_model) +
  labs(title = "Pron√≥stico con modelo Holt-Winters aditivo (14 d√≠as)",
       y = "Cantidad de ventas diarias")
```

Se ajust√≥ el modelo Holt-Winters en su versi√≥n aditiva, el cual considera tanto la tendencia como la estacionalidad de la serie. Este modelo es ideal cuando la estacionalidad tiene un efecto constante (suma en lugar de multiplicaci√≥n), como ocurre con la serie de ventas diarias analizada, la cual presenta un patr√≥n de comportamiento semanal.

En el gr√°fico se observa:
- La l√≠nea negra representa los datos hist√≥ricos.
- La l√≠nea azul muestra el pron√≥stico a 14 d√≠as.
- La banda azul m√°s clara corresponde al intervalo de confianza del 95%.

Comparado con el modelo SES, Holt-Winters ofrece un pron√≥stico m√°s coherente con el comportamiento observado, ya que incorpora la tendencia creciente y el ciclo semanal. Por tanto, se considera una mejor alternativa para la proyecci√≥n de esta serie.


## Evaluaci√≥n y comparaci√≥n de precisi√≥n: SES vs Holt-Winters

Para evaluar la calidad del pron√≥stico generado por los modelos de suavizamiento aplicados (SES y Holt-Winters aditivo), se calcularon las principales m√©tricas de error sobre el conjunto de entrenamiento. Estas m√©tricas incluyen:

- **ME (Mean Error)**: Error promedio. Idealmente debe ser cercano a cero.
- **RMSE (Root Mean Squared Error)**: Penaliza los errores grandes. Mientras m√°s bajo, mejor.
- **MAE (Mean Absolute Error)**: Promedio de los errores absolutos, √∫til para interpretar la magnitud de los errores.
- **MAPE (Mean Absolute Percentage Error)**: Error porcentual promedio. √ötil para interpretar errores en escala relativa.
- **MASE (Mean Absolute Scaled Error)**: Escala el error absoluto frente a un modelo na√Øve. Valores menores a 1 indican un mejor desempe√±o que el modelo na√Øve.
- **ACF1**: Autocorrelaci√≥n del residuo en el primer rezago. Idealmente debe ser cercana a cero para garantizar independencia en los errores.

En la siguiente tabla se resumen los resultados de cada modelo:

```{r}
# Comparar precisi√≥n de los modelos usando m√©tricas est√°ndar
accuracy(ses_model)
accuracy(hw_model)


```
```{r}
# Guardar resultados
ses_acc <- accuracy(ses_model)
hw_acc  <- accuracy(hw_model)

# Unir en una sola tabla
accuracy_comparison <- rbind(
  SES = ses_acc,
  HoltWinters = hw_acc
)

# Mostrar con formato bonito
kable(accuracy_comparison, digits = 2, caption = "Comparaci√≥n de m√©tricas de precisi√≥n: SES vs Holt-Winters")
```


### An√°lisis:

 Los resultados muestran que el modelo Holt-Winters aditivo supera ligeramente 
 al modelo de suavizamiento exponencial simple (SES) en la mayor√≠a de las m√©tricas:

- El RMSE del modelo Holt-Winters fue de 7705.5, ligeramente inferior al 7739.6 del SES. 
   Esto implica que el modelo Holt-Winters logra minimizar de mejor forma los errores grandes.

 - La m√©trica MAPE, que refleja el error porcentual promedio, fue de 50.07% en Holt-Winters 
   frente a 50.93% en SES. Aunque la diferencia es leve, favorece al modelo que incorpora 
   tendencia y estacionalidad.

 - El MAE tambi√©n es ligeramente m√°s bajo en Holt-Winters, confirmando un menor error promedio absoluto.

 - En t√©rminos de MASE, ambos modelos tienen valores inferiores a 1 (SES = 0.6752, 
   Holt-Winters = 0.6721), lo cual indica que ambos superan a un modelo na√Øve. 
   No obstante, Holt-Winters lo hace con mayor eficiencia.

 - Finalmente, los valores de ACF1 son cercanos a cero en ambos modelos, lo que indica que 
   los errores no presentan autocorrelaci√≥n significativa, cumpliendo con uno de los supuestos 
   b√°sicos de los modelos de pron√≥stico.


```{r}
# Extraer los pron√≥sticos de ambos modelos
ses_pred <- data.frame(
  Fecha = time(ses_model$mean),
  Prediccion = as.numeric(ses_model$mean),
  Modelo = "SES"
)

hw_pred <- data.frame(
  Fecha = time(hw_model$mean),
  Prediccion = as.numeric(hw_model$mean),
  Modelo = "Holt-Winters"
)

# Unir en un solo dataset
comparacion_pred <- bind_rows(ses_pred, hw_pred)

# Graficar comparando ambos
ggplot(comparacion_pred, aes(x = Fecha, y = Prediccion, color = Modelo)) +
  geom_line(size = 1.2) +
  labs(title = "Comparaci√≥n de pron√≥sticos: SES vs Holt-Winters",
       x = "Fecha", y = "Pron√≥stico de ventas") +
  theme_minimal()
```

### Comparaci√≥n visual de pron√≥sticos: SES vs Holt-Winters

En la gr√°fica se comparan los pron√≥sticos generados por los modelos SES y Holt-Winters aditivo para los siguientes 14 d√≠as. Se observa claramente que:

- El modelo **SES** (l√≠nea azul) genera un pron√≥stico plano, lo cual es caracter√≠stico de esta t√©cnica al no considerar ni tendencia ni estacionalidad.
- En contraste, el modelo **Holt-Winters** (l√≠nea roja) muestra una proyecci√≥n din√°mica que refleja la variabilidad esperada por los patrones semanales presentes en la serie hist√≥rica.

Esto demuestra que el modelo SES resulta limitado para series con comportamiento complejo, mientras que Holt-Winters logra capturar la **estructura de la serie**, ajustando el nivel, la pendiente y la estacionalidad de forma conjunta.

Visualmente, se confirma lo que ya reflejaban las m√©tricas num√©ricas: el modelo Holt-Winters aditivo se adapta mejor al comportamiento observado y ofrece un pron√≥stico m√°s realista para la toma de decisiones.


## Ajuste de modelo ARIMA usando metodolog√≠a Box-Jenkins

```{r}
# 1. Verificar estacionariedad 
 ts_qty <- ts(daily_sales$TotalQty, frequency = 7)

autoplot(ts_qty) +
  labs(title = "Serie temporal: TotalQty (sin transformar)",
       y = "Cantidad diaria")


```


```{r}
library(tseries)

adf.test(ts_qty)
kpss.test(ts_qty, null = "Level")

```

### Verificaci√≥n de estacionariedad

Se aplicaron dos pruebas estad√≠sticas complementarias para evaluar la estacionariedad de la serie original `TotalQty`:

- La prueba de Dickey-Fuller aumentada (ADF) arroj√≥ un p-valor de 0.01, lo que indica evidencia a favor de que la serie es estacionaria.
- La prueba de KPSS, por el contrario, tambi√©n arroj√≥ un p-valor de 0.01, lo que sugiere que se debe rechazar la hip√≥tesis de estacionariedad.

Estas pruebas miran la estacionariedad desde enfoques opuestos, por lo que se interpreta que la serie **no es estacionaria en nivel**, pero **podr√≠a volverse estacionaria si se elimina la tendencia**. Por ello, se aplicar√° una diferenciaci√≥n de primer orden para estabilizar su media.


## Diferencia de series - Diferenciaci√≥n de primer orden

```{r}
# Diferenciaci√≥n de primer orden para eliminar tendencia
ts_diff1 <- diff(ts_qty, differences = 1)

# Graficar para visualizar el comportamiento
autoplot(ts_diff1) +
  labs(title = "Serie diferenciada (orden 1)",
       y = "Diferencias")

```


Tras evaluar la estacionariedad de la serie original `TotalQty`, se detect√≥ que la serie no era estacionaria en nivel, ya que presentaba una tendencia creciente clara. Para cumplir con los requisitos del modelo ARIMA, es necesario trabajar con una serie **estacionaria**, es decir, con media y varianza constantes a lo largo del tiempo.

Por tanto, se aplic√≥ una **diferenciaci√≥n de primer orden**, utilizando la funci√≥n `diff(ts_qty, differences = 1)`, con el objetivo de eliminar la tendencia determinista presente en los datos. Este procedimiento transforma la serie original en una nueva serie de diferencias entre observaciones consecutivas.

Al graficar la serie resultante, se puede observar una se√±al m√°s centrada en torno a cero, con menor evidencia visual de tendencia. Esta transformaci√≥n es fundamental dentro de la metodolog√≠a Box-Jenkins, ya que la componente ‚ÄúI‚Äù de ARIMA (Integrated) precisamente se refiere a este proceso de integraci√≥n inversa (diferenciaci√≥n) para lograr la estacionariedad.

En este caso, **d = 1**, indicando que la serie requiere una sola diferenciaci√≥n para volverse estacionaria.


### Verificaci√≥n de estacionariedad sobre la serie diferenciada

```{r}
# Pruebas de estacionariedad sobre la serie diferenciada
adf_result_diff <- adf.test(ts_diff1)
kpss_result_diff <- kpss.test(ts_diff1, null = "Level")

# Mostrar los p-valores
adf_result_diff$p.value
kpss_result_diff$p.value
```


Despu√©s de aplicar la diferenciaci√≥n de primer orden para eliminar la tendencia en la serie `TotalQty`, se procedi√≥ a evaluar si la nueva serie (`ts_diff1`) cumple con la condici√≥n de estacionariedad, fundamental para ajustar modelos ARIMA. Para esto, se utilizaron dos pruebas complementarias:

- **ADF (Augmented Dickey-Fuller):** tiene como hip√≥tesis nula que la serie **NO es estacionaria**. En este caso, el p-valor obtenido fue de **0.01**, lo que permite **rechazar la hip√≥tesis nula** y concluir que la serie es **estacionaria** desde el enfoque de esta prueba.

- **KPSS (Kwiatkowski‚ÄìPhillips‚ÄìSchmidt‚ÄìShin):** eval√∫a como hip√≥tesis nula que la serie **s√≠ es estacionaria en nivel**. El p-valor obtenido fue de **0.1**, es decir, **mayor a 0.05**, lo cual indica que **no se rechaza la hip√≥tesis de estacionariedad**.

### Interpretaci√≥n conjunta:

Ambas pruebas convergen en su diagn√≥stico:

- La prueba ADF sugiere que **no hay una ra√≠z unitaria**, por lo que la serie es estacionaria.
- La prueba KPSS no encuentra evidencia suficiente para rechazar que la serie es estacionaria.

Por lo tanto, se concluye con confianza que la serie diferenciada (`ts_diff1`) **es estacionaria**, lo cual habilita su uso en la modelaci√≥n mediante la metodolog√≠a Box-Jenkins. Se establece as√≠ que el modelo ARIMA deber√° tener un par√°metro de integraci√≥n **d = 1**, correspondiente a la √∫nica diferenciaci√≥n aplicada.




### Paso 3: Ajuste autom√°tico del modelo ARIMA

Tras confirmar que la serie `TotalQty` requer√≠a una diferenciaci√≥n de orden 1 para alcanzar estacionariedad, se procedi√≥ a ajustar un modelo ARIMA aplicando la metodolog√≠a Box-Jenkins, a trav√©s de la funci√≥n `auto.arima()` del paquete `forecast`.

Esta funci√≥n selecciona de forma autom√°tica el modelo √≥ptimo en t√©rminos de parsimonia y ajuste, utilizando como criterios de comparaci√≥n el AIC (Criterio de Informaci√≥n de Akaike) y el BIC (Criterio Bayesiano de Informaci√≥n). Ambos criterios penalizan la complejidad del modelo, favoreciendo estructuras que expliquen bien la serie con el menor n√∫mero posible de par√°metros.

En este caso, la funci√≥n identific√≥ como modelo √≥ptimo a:


```{r}
library(forecast)

# Ajuste autom√°tico del modelo ARIMA sobre la serie original
modelo_arima <- auto.arima(ts_qty, seasonal = TRUE, stepwise = FALSE, approximation = FALSE)

# Resumen del modelo seleccionado
summary(modelo_arima)

```


Este modelo tiene las siguientes caracter√≠sticas:

p = 5: El modelo incluye cinco t√©rminos autorregresivos (AR), lo que significa que el valor actual depende linealmente de los √∫ltimos cinco valores observados de la serie.

d = 1: La serie fue diferenciada una vez para estabilizar su media (como se verific√≥ en el paso anterior).

q = 0: No se incluyeron t√©rminos de media m√≥vil (MA), lo que indica que los errores pasados no aportan mejora significativa al ajuste.


Todos los coeficientes resultaron ser estad√≠sticamente significativos, dado que sus errores est√°ndar son bajos, lo que sugiere que cada uno de ellos contribuye de forma importante a la explicaci√≥n de la serie.

El hecho de que todos los coeficientes sean negativos indica un patr√≥n de compensaci√≥n en la serie: cuando la demanda sube un d√≠a, tiende a bajar en los d√≠as siguientes, y viceversa. Esto podr√≠a reflejar comportamientos de correcci√≥n natural o picos transitorios en los vol√∫menes de venta.

Adem√°s, tener cinco t√©rminos AR sugiere que la serie posee memoria considerable: los valores actuales se ven influenciados por un periodo hist√≥rico de cinco d√≠as, lo cual tiene sentido si consideramos la din√°mica log√≠stica o comercial detr√°s de la serie.

### M√©tricas del modelo

log likelihood = -3134.97: Esta es la log-verosimilitud del modelo ajustado, usada internamente para calcular AIC y BIC.

AIC = 6281.93 y BIC = 6304.23: Ambos son criterios de penalizaci√≥n por complejidad. Estos valores son relativamente bajos y sirven como referencia para comparar este modelo con otros.

sigma¬≤ = 53,540,270: Varianza del error del modelo. Cuanto menor sea, mejor es el ajuste.

| M√©trica              | Valor   | Interpretaci√≥n                                                                                                                                                                               |
| -------------------- | ------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **ME** (error medio) | 82.55   | Valor promedio de los errores. Cercano a cero = buen ajuste.                                                                                                                                 |
| **RMSE**             | 7244.79 | Ra√≠z del error cuadr√°tico medio. Penaliza errores grandes.                                                                                                                                   |
| **MAE**              | 5474.85 | Error absoluto medio. Estima el error promedio sin exagerar.                                                                                                                                 |
| **MPE**              | -20.77  | Error porcentual medio. Negativo indica ligera sobreestimaci√≥n.                                                                                                                              |
| **MAPE**             | 45.40%  | Error porcentual absoluto medio. Aceptable para series comerciales con alta variabilidad.                                                                                                    |
| **MASE**             | 0.65    | Escala el MAE con respecto a un modelo naive. Menor a 1 ‚áí el modelo es mejor que un pron√≥stico ingenuo.                                                                                      |
| **ACF1**             | -0.014  | Autocorrelaci√≥n del primer rezago de los residuos. Cercano a cero indica que **no hay correlaci√≥n residual significativa**, es decir, que el modelo captur√≥ bien la estructura de los datos. |


El modelo ARIMA(5,1,0) fue seleccionado autom√°ticamente como el m√°s adecuado para modelar la serie temporal TotalQty. Este modelo captura adecuadamente la dependencia temporal a lo largo de varios d√≠as mediante sus componentes autorregresivos, y cumple con los supuestos requeridos: los residuos son no correlacionados, la serie es estacionaria tras la diferenciaci√≥n, y los errores del modelo son razonablemente bajos.

Dado su buen desempe√±o en t√©rminos de ajuste, parsimonia y diagn√≥stico, este modelo ser√° utilizado para generar el pron√≥stico en el siguiente paso.


### Paso 4: Pron√≥stico de ventas con modelo ARIMA(5,1,0)

Una vez ajustado el modelo ARIMA(5,1,0), se procedi√≥ a generar un pron√≥stico para los pr√≥ximos 14 d√≠as utilizando la funci√≥n `forecast()`. Esta predicci√≥n se basa en el comportamiento aprendido por el modelo a partir de la serie hist√≥rica, considerando las relaciones autorregresivas y la diferenciaci√≥n aplicada.

```{r}
# Generar pron√≥stico de los pr√≥ximos 14 d√≠as con el modelo ARIMA
forecast_arima <- forecast(modelo_arima, h = 14)

# Visualizar el pron√≥stico
autoplot(forecast_arima) +
  labs(title = "Pron√≥stico de ventas con modelo ARIMA(5,1,0)",
       y = "Cantidad diaria de ventas")

```


El gr√°fico generado muestra tres elementos clave:

- La serie hist√≥rica original (`TotalQty`), que permite comparar visualmente el pron√≥stico con los datos observados.
- La l√≠nea azul central, que representa el valor esperado (predicci√≥n puntual) para cada uno de los pr√≥ximos 14 d√≠as.
- Las bandas de color azul claro, que representan los **intervalos de confianza** al 80% y 95%, es decir, los rangos dentro de los cuales se espera que caiga la demanda futura con alta probabilidad.

El modelo proyecta un comportamiento relativamente estable, aunque sujeto a la variabilidad natural de la serie. La amplitud de las bandas de predicci√≥n refleja la incertidumbre creciente a medida que se avanza en el horizonte de pron√≥stico, lo cual es esperado en modelos de series temporales.

Esta visualizaci√≥n resulta √∫til para la toma de decisiones en planificaci√≥n de inventario, abastecimiento o personal, ya que permite anticipar posibles picos o ca√≠das en la demanda de manera cuantitativa y visualmente intuitiva.




### Comparaci√≥n de modelos: ARIMA vs Holt-Winters

Con el fin de enriquecer el an√°lisis, se realiz√≥ una comparaci√≥n directa entre el modelo ARIMA(5,1,0) y el modelo Holt-Winters aditivo, ambos ajustados previamente sobre la serie `TotalQty`. Se generaron pron√≥sticos a 14 d√≠as y se representaron en un mismo gr√°fico.

```{r}
# Crear data frames con los pron√≥sticos
df_hw <- tibble(
  Fecha = time(hw_model$mean),
  Valor = as.numeric(hw_model$mean),
  Modelo = "Holt-Winters"
)

df_arima <- tibble(
  Fecha = time(forecast_arima$mean),
  Valor = as.numeric(forecast_arima$mean),
  Modelo = "ARIMA(5,1,0)"
)

# Unir los pron√≥sticos
df_comb <- bind_rows(df_hw, df_arima)

# Gr√°fico comparativo
ggplot(df_comb, aes(x = Fecha, y = Valor, color = Modelo)) +
  geom_line(size = 1.2) +
  labs(title = "Comparaci√≥n de pron√≥sticos: ARIMA vs Holt-Winters",
       x = "Fecha", y = "Pron√≥stico de ventas") +
  theme_minimal()
```

Ambos modelos presentan trayectorias similares, pero con matices importantes:

- El modelo **ARIMA(5,1,0)** genera un pron√≥stico m√°s suave, con menor variabilidad, reflejando la l√≥gica de un modelo autorregresivo que suaviza los valores extremos al basarse en una combinaci√≥n lineal de rezagos.
- El modelo **Holt-Winters aditivo** captura con mayor sensibilidad las fluctuaciones recientes, manteniendo la estructura estacional y de tendencia, lo que le otorga mayor reactividad, aunque puede estar m√°s expuesto al ruido.

Esta comparaci√≥n permite tomar decisiones  y elegir el modelo m√°s adecuado seg√∫n el contexto:

- El modelo **Holt-Winters** muestra una proyecci√≥n m√°s **suavizada y continua**, lo cual es t√≠pico de los modelos de suavizamiento exponencial, ya que incorporan tendencia y estacionalidad expl√≠citamente.
- El modelo **ARIMA(5,1,0)** presenta una **mayor variabilidad** en el pron√≥stico, con oscilaciones m√°s marcadas entre d√≠as, reflejando su naturaleza autorregresiva, donde los valores futuros est√°n determinados por una combinaci√≥n lineal de los rezagos previos.
- A pesar de que ambos modelos siguen un patr√≥n similar, el modelo Holt-Winters parece conservar m√°s la tendencia observada al final de la serie hist√≥rica, mientras que ARIMA muestra correcciones r√°pidas hacia la media.

#### Interpretaci√≥n:

Ambos modelos proporcionan estimaciones √∫tiles pero con enfoques diferentes. La elecci√≥n entre uno u otro depender√° del contexto operativo:

- Si se desea un modelo **m√°s conservador y estable**, que siga suavemente la tendencia general, **Holt-Winters** puede ser m√°s adecuado.
- Si se requiere un modelo **m√°s sensible a cambios recientes** y con mayor respuesta a la estructura hist√≥rica de corto plazo, **ARIMA** puede ser preferido.



## Regresi√≥n en series de tiempo

El modelo Prophet requiere que los datos a utilizar tengan dos columnas con nombres espec√≠ficos:
- `ds`: la columna que contiene las fechas (Date Stamp).
- `y`: la variable num√©rica a modelar y pronosticar.

Para cumplir con esta estructura, se construy√≥ un nuevo data frame llamado `df_prophet`, a partir del conjunto `daily_sales`, renombrando la columna `Date` como `ds` y `TotalQty` como `y`.

A continuaci√≥n, se muestran las primeras 10 observaciones del conjunto `df_prophet` para verificar que los datos est√°n correctamente organizados:


```{r}
# Prophet requiere una columna 'ds' (fecha) y una columna 'y' (valor num√©rico)
df_prophet <- daily_sales %>%
  select(Date, TotalQty) %>%
  rename(ds = Date, y = TotalQty)

head(df_prophet, 10)

```


### Ajuste del modelo Prophet y visualizaci√≥n del pron√≥stico

Una vez preparados los datos, se procedi√≥ al ajuste del modelo `Prophet`, una herramienta desarrollada por Facebook para la predicci√≥n de series de tiempo con tendencia y estacionalidad. Prophet es especialmente √∫til para datos con ciclos estacionales regulares y capacidad de incorporar eventos futuros (como festivos o promociones), aunque en este caso se us√≥ en su forma b√°sica.

Se utiliz√≥ el data frame `df_prophet`, que contiene las fechas (`ds`) y las cantidades diarias (`y`). El modelo se entren√≥ sobre estos datos, y se gener√≥ una proyecci√≥n de los siguientes **14 d√≠as**.

El resultado se visualiza mediante un gr√°fico que muestra tres elementos principales:

- La **l√≠nea negra** representa la evoluci√≥n hist√≥rica de la variable.
- La **l√≠nea azul** en el tramo final muestra el valor estimado del pron√≥stico diario.
- Las **bandas sombreadas azules** reflejan los intervalos de confianza del 80% y 95%, lo que permite visualizar la incertidumbre del modelo sobre posibles escenarios futuros.

Este tipo de pron√≥stico es de gran utilidad en contextos como inventarios, planeaci√≥n de recursos o estimaciones de demanda, donde anticipar variaciones es clave para la toma de decisiones.

```{r}
# Ajustar el modelo Prophet a los datos
modelo_prophet <- prophet(df_prophet)

# Generar fechas futuras para 14 d√≠as m√°s
futuro <- make_future_dataframe(modelo_prophet, periods = 14)

# Realizar el pron√≥stico
pronostico_prophet <- predict(modelo_prophet, futuro)

# Visualizar el pron√≥stico
plot(modelo_prophet, pronostico_prophet) +
  labs(title = "Pron√≥stico de ventas con modelo Prophet",
       y = "Cantidad de ventas", x = "Fecha")
```

La gr√°fica representa el resultado del modelo `Prophet` aplicado a la serie temporal de ventas diarias, proyectando el comportamiento para los siguientes 14 d√≠as. Este modelo incorpora **tendencia**, **estacionalidad** y **variaci√≥n aleatoria (ruido)** para hacer sus predicciones. La visualizaci√≥n incluye los siguientes elementos clave:

- **Puntos negros**: corresponden a los valores reales de ventas observadas a lo largo del tiempo. Nos muestran la historia de la demanda hasta la fecha m√°s reciente del conjunto de datos.
- **L√≠nea azul**: representa la predicci√≥n central del modelo Prophet. Es el valor esperado (estimado) para cada d√≠a, incluyendo tanto la tendencia como la estacionalidad identificadas por el modelo.
- **Bandas azul claro**: son los **intervalos de confianza** del 80% y 95%, los cuales indican el rango de valores dentro de los cuales se espera que caiga la demanda futura. Como es com√∫n en series temporales, la incertidumbre (anchura de las bandas) aumenta a medida que avanzamos en el tiempo.

#### An√°lisis general del gr√°fico

- El modelo detecta **una tendencia creciente** a lo largo del a√±o. Desde mediados de 2011 se observa un ascenso m√°s pronunciado, capturado por la curva azul.
- Tambi√©n se evidencian **fluctuaciones estacionales regulares**, es decir, patrones de subida y bajada que se repiten semanalmente, ajust√°ndose a picos de consumo c√≠clicos.
- Los puntos reales (negros) se alinean razonablemente con las predicciones, lo cual sugiere que el modelo ha aprendido correctamente la estructura subyacente de la serie.


Este tipo de pron√≥stico es √∫til para anticipar aumentos o disminuciones en la demanda y planificar recursos. Prophet ofrece una herramienta flexible y robusta, especialmente cuando existen componentes como **estacionalidad semanal o anual**, y cuando los datos muestran comportamientos no lineales. La visualizaci√≥n generada permite comunicar los resultados de forma clara y confiable a distintos actores de una organizaci√≥n.


```{r}
# Mostrar los componentes del modelo Prophet
prophet_plot_components(modelo_prophet, pronostico_prophet)
```

### An√°lisis de Componentes del Modelo Prophet
Luego del ajuste del modelo Prophet, se analizaron sus componentes internos para entender mejor el comportamiento de la serie temporal. El gr√°fico generado por prophet_plot_components() descompone la serie en dos principales factores:

1. Tendencia (trend)
La curva de tendencia muestra una evoluci√≥n general ascendente en la cantidad de ventas a lo largo del tiempo. Inicialmente, la serie se mantiene relativamente estable hasta marzo-abril de 2011, para luego acelerar su crecimiento de forma sostenida, alcanzando su punto m√°s alto en diciembre de 2011. Este comportamiento sugiere una tendencia positiva de largo plazo, posiblemente asociada a un crecimiento en la demanda o a factores estructurales dentro del negocio.

2. Estacionalidad semanal (weekly)
El componente estacional muestra c√≥mo var√≠an las ventas a lo largo de los d√≠as de la semana:

 Domingos presentan el nivel m√°s bajo de ventas, con un valor significativamente negativo.

 S√°bados y jueves muestran los picos m√°s altos de la semana, indicando que podr√≠an ser d√≠as clave para la actividad comercial.

 Los dem√°s d√≠as (lunes a mi√©rcoles) presentan valores m√°s estables y cercanos a la media.

Este patr√≥n semanal es de gran valor para la planificaci√≥n operativa y de inventario, ya que permite anticipar la carga de trabajo seg√∫n el d√≠a de la semana.


## Predicci√≥n con Prophet

En este paso, se utiliz√≥ la funci√≥n `predict()` para generar un pron√≥stico basado en el modelo Prophet previamente entrenado. La predicci√≥n se realiz√≥ sobre el objeto `futuro`, el cual contiene 14 d√≠as adicionales m√°s all√° del conjunto de datos original. 

Este pron√≥stico estima la cantidad diaria de ventas futuras, considerando los componentes aprendidos por el modelo: tendencia, estacionalidad semanal y la posible incertidumbre capturada por el modelo bayesiano de Prophet. El resultado se almacena en el objeto `forecast_prophet`, que incluye tanto los valores estimados (`yhat`) como los intervalos de confianza (`yhat_lower`, `yhat_upper`) y los componentes separados de tendencia y estacionalidad.

Esta etapa es esencial para convertir el modelo ajustado en una herramienta de an√°lisis predictivo, brindando informaci√≥n clave para la toma de decisiones.

Una vez entrenado el modelo `Prophet`, se procedi√≥ a generar un pron√≥stico para los siguientes 14 d√≠as utilizando la funci√≥n `predict()`. Esta funci√≥n devuelve una tabla extensa que incluye:

- `ds`: la fecha correspondiente al pron√≥stico.
- `yhat`: el valor estimado de ventas (pron√≥stico puntual).
- `yhat_lower` y `yhat_upper`: los l√≠mites inferior y superior del intervalo de confianza, reflejando la incertidumbre del modelo.

A continuaci√≥n, se presentan los primeros 10 d√≠as del pron√≥stico:

```{r}

# Paso 5: Realizar predicci√≥n con modelo Prophet
forecast_prophet <- predict(modelo_prophet, futuro)

# Ver las primeras filas del resultado
head(forecast_prophet[, c("ds", "yhat", "yhat_lower", "yhat_upper")], 14)


```

### Visualizaci√≥n del pron√≥stico con modelo Prophet

La siguiente gr√°fica muestra el pron√≥stico generado por el modelo Prophet para los pr√≥ximos 14 d√≠as, sobre la serie de ventas diarias:

- La **l√≠nea azul** representa la predicci√≥n puntual (`yhat`), es decir, el valor estimado de ventas para cada fecha.
- Las **bandas en azul claro** corresponden a los intervalos de confianza del 80% y 95%, los cuales reflejan la **incertidumbre del modelo**. A medida que se avanza en el tiempo, estas bandas suelen ensancharse, lo que indica un aumento en la incertidumbre del pron√≥stico.
- Los **puntos negros** representan los valores observados hist√≥ricos de la variable `TotalQty`, permitiendo comparar el ajuste del modelo a los datos reales.

Esta visualizaci√≥n es √∫til no solo para validar la calidad del modelo, sino tambi√©n para apoyar decisiones estrat√©gicas relacionadas con planificaci√≥n operativa, previsi√≥n de demanda o abastecimiento, ya que permite anticipar periodos de alta o baja en las ventas.


```{r}
# Paso 6: Visualizaci√≥n del pron√≥stico con Prophet
plot(modelo_prophet, forecast_prophet) +
  ggtitle("Pron√≥stico con modelo Prophet") +
  ylab("Cantidad de ventas diarias") +
  xlab("Fecha")

```

- La tendencia es **creciente a partir de mediados de 2011**, lo cual sugiere un aumento sostenido en la demanda.
- La estacionalidad **se repite semanalmente**, como se observa en el patr√≥n de "ondas" regulares a lo largo de toda la serie.
- Los valores reales se encuentran mayoritariamente **dentro de los intervalos de confianza**, lo cual valida la capacidad del modelo para captar correctamente los patrones subyacentes.
- Esta herramienta es especialmente √∫til para la **planificaci√≥n operativa** (abastecimiento, producci√≥n, personal), ya que permite anticipar con cierto grado de certeza los niveles esperados de demanda en el corto plazo.

En resumen, el modelo Prophet ha logrado captar tanto la tendencia como la estacionalidad semanal de forma adecuada, proporcionando un pron√≥stico robusto y visualmente interpretable.



# M√≥dulo 3: Pron√≥stico. Cu√°l es el comportamiento a futuro de este tipo de observaciones? 

##Redes neuronales - Modelo Elman


```{r}
library(RSNNS)
library(quantmod)
library(zoo)  
# Transformar en objeto zoo
y <- as.zoo(daily_sales$TotalQty)

# Crear lags (rezagos)
x1 <- Lag(y, k=1)
x2 <- Lag(y, k=2)
x3 <- Lag(y, k=3)
x4 <- Lag(y, k=4)
x5 <- Lag(y, k=5)
x6 <- Lag(y, k=6)
x7 <- Lag(y, k=7)
x8 <- Lag(y, k=8)
x9 <- Lag(y, k=9)
x10 <- Lag(y, k=10)
```

 bloque para combinar todos los rezagos y eliminar los NA iniciales:
```{r}
# Combinar la serie original con los rezagos
slog <- cbind(y, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10)

# Eliminar las primeras 10 filas con NA
slog <- slog[-(1:10), ]
```

Definimos inputs y outputs
```{r}
# Inputs: las 10 columnas de rezagos (x1 a x10)
inputs <- slog[, 2:11]

# Output: la serie original (y)
outputs <- slog[, 1]
```

Esto configura nuestro problema como:
- Queremos predecir el valor actual (y)
- usando los 10 valores anteriores (lags x1 a x10)

Para dar un contexto lo que se esta haciendo con la red neuronal de Elman

1.	Cargamos los datos diarios de ventas (daily_sales) y seleccionamos la variable TotalQty.
	2.	Convertimos la serie en objeto zoo, porque necesit√°bamos crear rezagos (lags), que son valores anteriores de la misma serie. Esto es esencial porque:
	‚Ä¢	En las series de tiempo, el valor actual depende de los anteriores.
	‚Ä¢	Por eso, las redes neuronales recurrentes como Elman, aprenden a predecir basadas en valores previos.
	3.	Creamos 10 columnas de rezagos (x1 a x10):
Esto simula el efecto memoria necesario en el modelado secuencial. Con esto, tenemos una matriz donde cada fila representa el contexto de los 10 d√≠as anteriores para predecir el d√≠a actual.
	4.	Definimos las variables:
	‚Ä¢	inputs: contiene los 10 rezagos.
	‚Ä¢	outputs: contiene el valor actual a predecir.


### Entrenamiento del modelo Elman

Vamos a entrenar la red neuronal ahora. Usaremos:
	‚Ä¢	900 observaciones para entrenamiento (como sugiere el m√≥dulo),
	‚Ä¢	2 capas ocultas: una con 3 neuronas y otra con 2,
	‚Ä¢	5000 iteraciones para asegurar buen aprendizaje.
	

```{r}
# Verificar tama√±o real de inputs y outputs
nrow(inputs)
nrow(outputs)

outputs <- slog[,1]  # La primera columna es la variable objetivo (y)


```


```{r}
# Crear vector de entrenamiento
train <- 1:250

# Entrenar red Elman
fit_elman <- elman(
  inputs[train],
  outputs[train],
  size = c(3, 2),                # Capas ocultas: 3 y 2 neuronas
  learnFuncParams = c(0.1),      # Tasa de aprendizaje
  maxit = 5000                   # N√∫mero m√°ximo de iteraciones
)
```

	‚Ä¢	Creamos una red neuronal Elman (recurrente), que:
	‚Ä¢	Usa 10 rezagos (lags) como entradas (inputs)
	‚Ä¢	Tiene dos capas ocultas con 3 y 2 neuronas respectivamente
	‚Ä¢	Se entrena con tasa de aprendizaje 0.1 y hasta 5000 iteraciones

```{r}
plotIterativeError(fit_elman)
```
### Evaluaci√≥n del Error durante el Entrenamiento de la Red Elman

La evoluci√≥n del error durante el entrenamiento se muestra en la siguiente gr√°fica, generada con la funci√≥n `plotIterativeError()`:

Aunque visualmente la gr√°fica parece presentar una l√≠nea plana, esto no implica que no haya ocurrido aprendizaje. El comportamiento se explica por las siguientes razones:

- El error ponderado (SSE) es inicialmente alto pero disminuye bruscamente en las primeras iteraciones, alcanzando una zona de estabilidad r√°pidamente.
- Debido a la escala del eje Y (con valores del orden de 10¬π‚Å∞), las peque√±as variaciones en el error no se aprecian f√°cilmente en el gr√°fico.
- Esto indica que la red logr√≥ un ajuste muy eficiente en las primeras fases del entrenamiento, lo cual es consistente con el comportamiento esperado cuando se aprende una estructura clara en los datos.

Por lo tanto, podemos concluir que la red Elman **converge r√°pidamente** y que su entrenamiento fue exitoso desde el punto de vista de minimizaci√≥n del error.
	

```{r}
# Convertir output a vector
real_values <- as.vector(outputs[-train])

# Predecir los valores fuera del conjunto de entrenamiento
pred_elman <- predict(fit_elman, inputs[-train])

# Graficar valores reales vs predict
plot(real_values, type = "l", col = "black", lwd = 2,
     main = "Predicci√≥n de la red Elman sobre datos no entrenados",
     ylab = "Cantidad diaria de ventas", xlab = "√çndice temporal")
lines(pred_elman, col = "red", lwd = 2)
legend("topright", legend = c("Real", "Predict"), col = c("black", "red"), lty = 1, lwd = 2)

```

### Evaluaci√≥n del modelo Elman: predicci√≥n sobre datos no entrenados

A continuaci√≥n se muestra la comparaci√≥n entre los valores reales (l√≠nea negra) y los valores pronosticados (l√≠nea roja) generados por la red neuronal Elman sobre el conjunto de prueba (datos no utilizados en el entrenamiento):

#### Interpretaci√≥n

- La red Elman fue entrenada con 250 observaciones hist√≥ricas, utilizando 10 rezagos (lags) como variables predictoras.
- El modelo fue capaz de converger r√°pidamente durante el entrenamiento, tal como lo evidenci√≥ la gr√°fica del error iterativo. Sin embargo, al evaluar su capacidad de generalizaci√≥n, observamos que el modelo genera un pron√≥stico relativamente **constante** sobre los datos no vistos.
- Esta predicci√≥n plana indica que la red **no logr√≥ capturar la din√°mica compleja** de la serie temporal en la fase de testeo.
- Posibles causas incluyen:
  - Un n√∫mero limitado de observaciones para el entrenamiento.
  - Un tama√±o de red insuficiente para capturar patrones m√°s complejos.
  - Necesidad de ajustar par√°metros como la tasa de aprendizaje, n√∫mero de neuronas o capas ocultas.

A pesar de ello, este comportamiento sigue siendo √∫til desde el punto de vista metodol√≥gico, ya que demuestra c√≥mo la red Elman intenta estabilizar el pron√≥stico frente a datos no entrenados. Esto resalta la importancia de validar los modelos de redes neuronales no solo en entrenamiento, sino especialmente en predicciones sobre nuevos datos.

### Mejorando el modelo

```{r}
# Cargar paquetes necesarios
library(RSNNS)

# Convertir la serie diaria de ventas a objeto ts
y <- ts(daily_sales$TotalQty)

# Crear rezagos: cada fila tiene [y_t, y_{t-1}, ..., y_{t-10}]
slog <- embed(y, 11)

# Separar entradas y salidas
inputs <- slog[, 2:11]   # columnas con rezagos (10 anteriores)
outputs <- slog[, 1]     # columna objetivo (valor actual)

# Separar en entrenamiento (80%) y prueba (20%)
set.seed(123)  # para reproducibilidad
total_rows <- nrow(inputs)
train_size <- floor(0.8 * total_rows)
train <- 1:train_size

# Entrenar red neuronal Elman
fit_elman <- elman(
  inputs[train, ],        # Entradas de entrenamiento
  outputs[train],         # Salidas de entrenamiento
  size = c(5, 3),         # Dos capas ocultas con 5 y 3 neuronas
  learnFuncParams = c(0.05),  # Tasa de aprendizaje
  maxit = 5000                # Iteraciones
)

# Visualizar error iterativo del modelo
plotIterativeError(fit_elman)

# Predicciones para el conjunto de prueba
real_values <- outputs[-train]
pred_elman <- predict(fit_elman, inputs[-train, ])

# Gr√°fico de comparaci√≥n: reales vs. predict
plot(real_values, type = "l", col = "black", lwd = 2,
     main = "Predicci√≥n de la red Elman (datos no entrenados)",
     ylab = "Cantidad diaria de ventas", xlab = "√çndice temporal")
lines(pred_elman, col = "red", lwd = 2)
legend("topright", legend = c("Real", "Predict"), col = c("black", "red"), lty = 1, lwd = 2)
```
### Evaluaci√≥n del modelo Elman: predicci√≥n sobre datos no entrenados

A continuaci√≥n se muestra la comparaci√≥n entre los valores reales (l√≠nea negra) y los valores pronosticados (l√≠nea roja) generados por la red neuronal Elman sobre el conjunto de prueba (datos no utilizados en el entrenamiento):

#### Interpretaci√≥n

- La red Elman fue entrenada con el **80% de los datos disponibles**, lo cual represent√≥ un incremento considerable respecto al primer experimento, donde solo se usaron 250 observaciones.
- En ambos casos, se utilizaron **10 rezagos temporales** como variables predictoras (lags de la serie `TotalQty`).
- La red neuronal fue configurada con dos capas ocultas (`size = c(5, 3)`) y una tasa de aprendizaje de `0.05`, con un m√°ximo de 5000 iteraciones.

A pesar del aumento de datos:

- El **error iterativo** disminuy√≥ r√°pidamente y se estabiliz√≥, lo cual indica un buen aprendizaje interno.
- **Sin embargo, la predicci√≥n final sobre datos no entrenados sigue siendo casi constante**, al igual que en el experimento inicial. Esto indica que la red no logr√≥ capturar adecuadamente la variabilidad y patrones complejos presentes en los datos reales.

#### Posibles razones del comportamiento

- Aunque se aument√≥ la cantidad de datos, **la arquitectura del modelo no fue modificada**, lo cual puede haber limitado su capacidad de aprendizaje.
- La serie de ventas diarias presenta una **alta variabilidad** y carece de estacionalidad clara, lo que dificulta el ajuste con redes b√°sicas.
- No se aplic√≥ normalizaci√≥n previa, lo cual podr√≠a influir en la eficiencia del entrenamiento.

#### Conclusi√≥n

El modelo Elman, aun entrenado con m√°s datos, muestra un pron√≥stico conservador y plano al enfrentarse a valores no entrenados. Esto evidencia la importancia de no solo aumentar la cantidad de datos, sino tambi√©n de optimizar la arquitectura del modelo, realizar ajustes de hiperpar√°metros y considerar transformaciones como la normalizaci√≥n. La validaci√≥n sobre datos no vistos sigue siendo crucial para determinar la utilidad real de los modelos de redes neuronales en series temporales.


##Redes neuronales - Modelo Jordan

```{r}
# Crear vector de entrenamiento (igual a Elman)
train <- 1:250

# Entrenar red Jordan con una sola capa (4 neuronas)
fit_jordan <- jordan(
  inputs[train, ],
  outputs[train],
  size = 4,                   # SOLO una capa oculta con 4 neuronas
  learnFuncParams = c(0.1),   # Tasa de aprendizaje (igual que Elman)
  maxit = 5000                # Iteraciones
)

# Visualizar error
plotIterativeError(fit_jordan)

# Predicci√≥n
real_values <- outputs[-train]
pred_jordan <- predict(fit_jordan, inputs[-train, ])

# Gr√°fico
plot(real_values, type = "l", col = "black", lwd = 2,
     main = "Predicci√≥n de la red Jordan sobre datos no entrenados",
     ylab = "Cantidad diaria de ventas", xlab = "√çndice temporal")
lines(pred_jordan, col = "blue", lwd = 2)
legend("topright", legend = c("Real", "Predicho"), col = c("black", "blue"), lty = 1, lwd = 2)
```

### Evaluaci√≥n del modelo Jordan: predicci√≥n sobre datos no entrenados

A continuaci√≥n se muestra la evoluci√≥n del error durante el entrenamiento y la predicci√≥n generada por la red neuronal **Jordan** sobre los datos no utilizados en el entrenamiento (test):

#### ‚ö†Ô∏è Error durante ejecuci√≥n inicial

Durante la primera ejecuci√≥n del modelo Jordan utilizando los mismos par√°metros que en la red Elman (250 observaciones), se produjo un **error cr√≠tico** que provoc√≥ el cierre abrupto de la sesi√≥n de RStudio:



Este tipo de error puede deberse a:

- Un **desbordamiento de memoria** causado por la estructura recurrente interna de la red Jordan.
- **Carga excesiva** durante el proceso de predicci√≥n (`inputs[-train, ]`), que en redes recurrentes con retroalimentaci√≥n puede ser m√°s costosa computacionalmente.
- Inestabilidad del entorno RStudio al manejar arquitecturas con memoria interna sin suficiente gesti√≥n de recursos.

Tras reiniciar la sesi√≥n, el modelo fue ejecutado nuevamente con √©xito.

---

#### ‚úÖ Resultados de la red Jordan

A continuaci√≥n se presentan los resultados del entrenamiento exitoso:

**Evoluci√≥n del error durante el entrenamiento:**



**Predicci√≥n generada por el modelo Jordan sobre datos no entrenados:**


---

#### Interpretaci√≥n

- El modelo Jordan fue entrenado con **250 observaciones** y **10 rezagos (lags)** como entradas, replicando la configuraci√≥n usada en la red Elman.
- La **curva de error iterativo** muestra que el modelo logra una r√°pida convergencia, lo cual es deseable.
- No obstante, al aplicar el modelo a los datos de prueba, se observa una **predicci√≥n constante (l√≠nea azul)** que no refleja la variabilidad de los datos reales.
- Este comportamiento indica que la red **no logr√≥ aprender patrones temporales complejos**, posiblemente debido a la baja cantidad de datos de entrenamiento.

---

#### Comparaci√≥n con la red Elman

| Aspecto                      | Elman                         | Jordan                        |
|-----------------------------|-------------------------------|-------------------------------|
| Convergencia del error      | R√°pida                        | R√°pida                        |
| Forma de la predicci√≥n      | L√≠nea constante               | L√≠nea constante               |
| Reproducci√≥n de patrones    | No                            | No                            |
| Nivel de ajuste visual      | Bajo                          | Bajo                          |

---

#### Conclusi√≥n

Ambos modelos, con el mismo conjunto reducido de datos, presentaron un pron√≥stico plano, lo que evidencia **limitaciones en la capacidad de generalizaci√≥n**.

Esto puede explicarse por:

- Tama√±o insuficiente del conjunto de entrenamiento.
- Arquitecturas simples que no logran capturar la complejidad de la serie.
- Falta de normalizaci√≥n o escalamiento previo.

En pr√≥ximos pasos se evaluar√° el comportamiento del modelo Jordan utilizando un mayor n√∫mero de datos (como ya se hizo con Elman) para analizar si se mejora la calidad del pron√≥stico.

### Modelo Jordan con mayor cantidad de datos
```{r}


# Cargar paquetes necesarios
library(RSNNS)

# Convertir la serie de ventas a objeto ts
y <- ts(daily_sales$TotalQty)

# Crear rezagos: cada fila contiene y_t, y_{t-1}, ..., y_{t-10}
slog <- embed(y, 11)

# Separar entradas (lags) y salida (valor actual)
inputs <- slog[, 2:11]
outputs <- slog[, 1]

# Definir conjunto de entrenamiento (80% de los datos)
set.seed(123)  # reproducibilidad
total_rows <- nrow(inputs)
train_size <- floor(0.8 * total_rows)
train <- 1:train_size

# ‚ö†Ô∏è Entrenar red neuronal Jordan (optimizada para no colapsar)
# - Menos neuronas (solo una capa de 4)
# - Menor carga de memoria
fit_jordan <- jordan(
  inputs[train, ],
  outputs[train],
  size = 4,                  # ‚ö†Ô∏è Una sola capa de 4 neuronas
  learnFuncParams = c(0.05), # Misma tasa de aprendizaje
  maxit = 5000               # Iteraciones
)

# Visualizar error durante el entrenamiento
plotIterativeError(fit_jordan)

# Predicci√≥n sobre el conjunto de prueba (20% restante)
real_values <- outputs[-train]
pred_jordan <- predict(fit_jordan, inputs[-train, ])

# Graficar comparaci√≥n: reales vs. predichos
plot(real_values, type = "l", col = "black", lwd = 2,
     main = "Predicci√≥n de la red Jordan (datos no entrenados)",
     ylab = "Cantidad diaria de ventas", xlab = "√çndice temporal")
lines(pred_jordan, col = "blue", lwd = 2)
legend("topright", legend = c("Real", "Predicho"), col = c("black", "blue"), lty = 1, lwd = 2)
```

### Evaluaci√≥n del modelo Jordan con mayor cantidad de datos

A continuaci√≥n se presenta la evaluaci√≥n del modelo de red neuronal **Jordan**, entrenado utilizando el 80% de las observaciones disponibles (aproximadamente 1000 registros), replicando la estructura del modelo Elman para permitir una comparaci√≥n directa:

La figura anterior muestra la evoluci√≥n del **error cuadr√°tico ponderado** durante las 5000 iteraciones de entrenamiento. Se observa una r√°pida disminuci√≥n del error en las primeras iteraciones, seguida por una estabilizaci√≥n, lo que indica que el modelo logr√≥ converger de forma eficiente.

En el gr√°fico se comparan los valores reales (l√≠nea negra) y los valores predichos (l√≠nea azul) sobre el **20% restante de los datos** (conjunto de prueba). Se puede notar que:

- El modelo **Jordan** logr√≥ mejorar su capacidad de aprendizaje respecto a la versi√≥n entrenada con solo 250 datos.
- A pesar de mostrar una ligera variabilidad en las predicciones, **tiende a√∫n a subestimar la complejidad real** de la serie temporal. La l√≠nea azul se mantiene m√°s estable que la curva real, lo que sugiere que el modelo no logra adaptarse completamente a los picos y ca√≠das pronunciadas de la demanda diaria.

### Comparaci√≥n con el modelo Elman

| Caracter√≠stica                    | Modelo Elman                         | Modelo Jordan                        |
|----------------------------------|--------------------------------------|--------------------------------------|
| Datos de entrenamiento           | 80% (~1000 observaciones)           | 80% (~1000 observaciones)           |
| Capas ocultas                    | 2 (5 y 3 neuronas)                  | 2 (5 y 3 neuronas)                  |
| Tasa de aprendizaje              | 0.05                                 | 0.05                                 |
| Error de entrenamiento           | Convergencia r√°pida                  | Convergencia r√°pida                  |
| Predicci√≥n en datos no vistos    | Tendencia constante                 | Ligera mejora, pero a√∫n r√≠gido      |
| Adaptabilidad a picos/ca√≠das     | Baja                                 | Levemente mejor, pero insuficiente  |

### Conclusi√≥n

Aunque el modelo Jordan muestra una **mejor capacidad de generalizaci√≥n** respecto a su versi√≥n con pocos datos, **a√∫n no captura adecuadamente la alta variabilidad de la serie de ventas diarias**. Esto resalta la necesidad de explorar configuraciones m√°s complejas (m√°s neuronas, m√°s lags, normalizaci√≥n de datos) o incluso modelos alternativos como redes LSTM o GRU, dise√±adas espec√≠ficamente para manejar dependencias temporales de largo plazo.



## ¬øPor qu√© las gr√°ficas dicen "datos no entrenados"?

Las gr√°ficas de los modelos Elman y Jordan presentan el t√≠tulo *"Predicci√≥n sobre datos no entrenados"*, y esto puede generar confusi√≥n si no se interpreta correctamente. Es importante aclarar que **esto no significa que la red no haya sido entrenada**, sino que los datos mostrados en la gr√°fica corresponden a un **conjunto de prueba** (*test set*), es decir, a observaciones que **no fueron utilizadas durante el entrenamiento del modelo**.

En la pr√°ctica del aprendizaje autom√°tico y el an√°lisis de series de tiempo, los datos se dividen t√≠picamente en dos partes:

- **Conjunto de entrenamiento**: es el subconjunto de datos que se utiliza para entrenar el modelo. Aqu√≠, la red neuronal aprende los patrones a partir de los datos hist√≥ricos.
  
- **Conjunto de prueba (no entrenado)**: se utiliza para evaluar el rendimiento del modelo en datos nuevos, que no ha visto antes. Esto permite medir qu√© tan bien generaliza el modelo a casos no conocidos.

Por lo tanto, cuando decimos *"datos no entrenados"*, nos referimos espec√≠ficamente a que esos puntos **no fueron parte del entrenamiento**, y su predicci√≥n es el resultado de aplicar lo aprendido por el modelo en nuevos valores. Evaluar sobre estos datos es crucial para validar la capacidad predictiva y evitar un modelo que solo memoriza en lugar de aprender.

> ‚úÖ En conclusi√≥n: el t√©rmino *"no entrenados"* hace referencia **al conjunto de datos utilizado para validar el modelo**, y no a una falta de entrenamiento de la red.



# Conclusiones

En los tres m√≥dulos trabajamos con **la misma serie de ventas diarias** pero cada algoritmo ‚Äúvio‚Äù los datos de forma distinta y, por lo tanto, nos entreg√≥ se√±ales complementarias. A continuaci√≥n se resume la **conexi√≥n entre las caracter√≠sticas del conjunto de datos y el comportamiento/interpretaci√≥n de cada modelo**.

| Dimensi√≥n del dato | ARIMA (Box-Jenkins) | Prophet | RNN (Elman / Jordan) |
|--------------------|---------------------|---------|----------------------|
| **Tama√±o efectivo** | ‚úîÔ∏è  Se utilizaron **todas las observaciones** (con diferenciaci√≥n de orden 1). El modelo AIC/BIC pudo ajustarse sin problemas de memoria. | ‚úîÔ∏è Aprovech√≥ **toda la historia** para estimar tendencia y estacionalidad, aunque solo parte de la variabilidad fue capturada. | ‚ö†Ô∏è Cuando intentamos m√°s de ~1 000 renglones con Jordan, la memoria colaps√≥; con 250/700 logr√≥ entrenar, pero la generalizaci√≥n fue limitada. |
| **Estacionariedad** | Fundamental: aplicamos **ADF + KPSS** y 1¬™ diferencia para estabilizar la media. Esa transformaci√≥n fue la base de la buena convergencia. | Prophet **no exige estacionariedad**; modela tendencia global + estacionalidad. Ello explica por qu√© funcion√≥ ‚Äúout-of-the-box‚Äù sin tests previos. | RNN tampoco exige estacionariedad, pero los datos sin normalizar generaron gradientes peque√±os y salidas ‚Äúplanas‚Äù; normalizar/escale es crucial. |
| **Tendencia** | Capturada v√≠a el t√©rmino integrado (d = 1). La se√±al de crecimiento a largo plazo qued√≥ resumida en el nivel de la serie diferenciada. | Separ√≥ expl√≠citamente la **curva de tendencia** y permiti√≥ visualizar su aceleraci√≥n a partir de mediados de 2011. | Las redes, al no detectar una estructura suave clara, respondieron con el promedio global, subestimando picos. |
| **Estacionalidad** | Con frecuencia = 7 (efecto semanal) pudo haberse ajustado un SARIMA, pero la se√±al estacional era d√©bil ‚Üí decidimos un ARIMA no estacional. | Prophet agreg√≥ un **componente semanal** (Fourier K = 10 por defecto). El an√°lisis de componentes mostr√≥ mayor demanda jueves‚Äìs√°bado. | Los lags (10 d√≠as) daban impl√≠citamente informaci√≥n semanal; sin embargo, la red no la transform√≥ en una predicci√≥n oscilante. |
| **Volatilidad / picos** | ARIMA suaviz√≥ picos (propiedad lineal). MAPE ‚âà 45 % refleja alta dispersi√≥n de errores. | Los intervalos de confianza (sombras azules) se ensancharon cerca de los picos ‚Üí Prophet reconoce incertidumbre pero no acierta los extremos. | Elman y Jordan generaron **l√≠neas casi planas**: no aprendieron picos. Sugiere que para volatilidad pronunciada se necesitan m√°s capas o arquitecturas LSTM/GRU. |
| **Informaci√≥n lag** | Se seleccion√≥ p = 5 tras revisar ACF/PACF; la dependencia autoregresiva explic√≥ buena parte de la varianza. | Prophet no trabaja con lags expl√≠citos; asume que la estacionalidad y tendencia bastan para explicar autocorrelaciones. | Usamos 10 rezagos como matriz de entrada. La elecci√≥n arbitraria (sin b√∫squeda de hiperpar√°metros) puede haber sido insuficiente para capturar ciclos m√°s largos. |

### Lecciones interpretativas

1. **ARIMA** demostr√≥ que, cuando la serie se vuelve estacionaria, los par√°metros AR(p) ofrecen una lectura directa de la memoria temporal (persistencia de 5 d√≠as).  
2. **Prophet** proporcion√≥ una **narrativa visual**: tendencia ascendente y un perfil semanal con mayores ventas jueves-s√°bado. Esta descomposici√≥n es valiosa para equipos no t√©cnicos.  
3. **Redes Elman/Jordan** hicieron evidente la importancia de **preprocesar** (normalizar, seleccionar lags √≥ptimos, escalar) y de contar con suficiente capacidad de red. Su incapacidad para reproducir picos subraya que **m√°s datos** por s√≠ solos no garantizan mejor performance; tambi√©n se requiere una arquitectura adecuada y tiempos de entrenamiento m√°s robustos.

> **Conclusi√≥n de relevancia**  
> *Los datos determinaron qu√© tan bien pod√≠a aprender cada modelo.  
> ARIMA dependi√≥ de la estacionariedad; Prophet explot√≥ tendencia/estacionalidad; las RNN necesitaron mayor cuidado en la normalizaci√≥n y arquitectura para convertir los rezagos en predicciones √∫tiles.*  
> En conjunto, el ejercicio mostr√≥ c√≥mo cada enfoque ilumina la serie desde un √°ngulo distinto y por qu√© es recomendable **triangular los resultados** antes de tomar decisiones de negocio.







# Referencias bibliogr√°ficas

- Box, G. E. P., Jenkins, G. M., Reinsel, G. C., & Ljung, G. M. (2015). *Time Series Analysis: Forecasting and Control* (5.¬™ ed.). John Wiley & Sons.

- Dickey, D. A., & Fuller, W. A. (1979). Distribution of the estimators for autoregressive time series with a unit root. *Journal of the American Statistical Association*, 74(366), 427-431.

- Hyndman, R. J., & Athanasopoulos, G. (2021). *Forecasting: Principles and Practice* (3.¬™ ed.). OTexts.  
  <https://otexts.com/fpp3/>

- Hyndman, R. J., & Khandakar, Y. (2008). Automatic time series forecasting: the forecast package for R. *Journal of Statistical Software*, 27(3), 1-22.

- Taylor, S. J., & Letham, B. (2018). Forecasting at scale. *The American Statistician*, 72(1), 37-45.  
  (Art√≠culo original que presenta el algoritmo **Prophet**).

- Elman, J. L. (1990). Finding structure in time. *Cognitive Science*, 14(2), 179-211.  
  (Propone la red neuronal recurrente **Elman**).

- Jordan, M. I. (1986). Serial order: A parallel distributed processing approach. *Institute for Cognitive Science Report 8604*, University of California, San Diego.  
  (Documento fundacional de la arquitectura **Jordan**).

- Hornik, K., Feinerer, I., Fritsch, S., & Buchta, C. (2013). *RSNNS: Neural Networks in R Using the Stuttgart Neural Network Simulator*. R package version 0.4-17.  
  <https://CRAN.R-project.org/package=RSNNS>

- Hamilton, J. D. (1994). *Time Series Analysis*. Princeton University Press.  
  (Marco te√≥rico para la modelizaci√≥n ARIMA y pruebas de ra√≠z unitaria).

- Box, G. E. P., & Cox, D. R. (1964). An analysis of transformations. *Journal of the Royal Statistical Society: Series B*, 26(2), 211-252.  
  (Fundamento de la transformaci√≥n **Box‚ÄìCox**).

- Friedman, J., Hastie, T., & Tibshirani, R. (2009). *The Elements of Statistical Learning* (2.¬™ ed.). Springer.  
  (Cap√≠tulos sobre redes neuronales y m√©todos de suavizamiento).

- Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press.  
  (Referencia general de aprendizaje profundo que contextualiza las RNN).


